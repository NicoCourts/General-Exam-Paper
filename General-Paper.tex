\documentclass[12pt]{article}

\usepackage{setspace}

\usepackage{graphicx, color, fancyhdr, tikz-cd, enumitem, framed, adjustbox, bbm, upgreek, xcolor, manfnt}
\usepackage[framed,thmmarks]{ntheorem}
\usepackage[framemethod=tikz]{mdframed}
\usepackage{hyperref}

\hypersetup{
	colorlinks = true,
	linkcolor = [rgb]{0,0,0.5},
	citecolor = [rgb]{0.6,0,0},
	urlcolor = [rgb]{0,0,0.5}
}
\usepackage[style=alphabetic, bibencoding=utf8]{biblatex}
%Set the bibliography file
\bibliography{sources}

\usepackage[T1]{fontenc}
\usepackage[urw-garamond]{mathdesign}
\usepackage{garamondx}
\let\mathcal\relax
\newcommand{\mathcal}[1]{\text{\usefont{OMS}{cmsy}{m}{n}#1}}

%Document-Specific includes
\usepackage{ytableau}
\usepackage{mathtools}
\usepackage{scalerel}

%Replacement for the old geometry package
\usepackage{fullpage}
\usepackage{amsmath}

%Input my definitions
\input{./mydefs.tex}

%Shade definitions
\theoremindent0cm
\theoremheaderfont{\normalfont\bfseries} 
\def\theoremframecommand{\colorbox[rgb]{0.9,1,.8}}
\newshadedtheorem{defn}[thm]{Definition}

%Set apart my theorems and lemmas and such
\surroundwithmdframed[outerlinewidth=0.4pt,
  innerlinewidth=0.5pt,
  middlelinewidth=1pt,
  middlelinecolor=white,
  topline=false,bottomline=false,rightline=false,leftmargin=2em]{thm}
\surroundwithmdframed[outerlinewidth=0.4pt,
  innerlinewidth=0.5pt,
  middlelinewidth=1pt,
  middlelinecolor=white,
  topline=false,bottomline=false,rightline=false,leftmargin=2em]{lem}
\surroundwithmdframed[outerlinewidth=0.4pt,
  innerlinewidth=0.5pt,
  middlelinewidth=1pt,
  middlelinecolor=white,
  topline=false,bottomline=false,rightline=false,leftmargin=2em]{cor}
  \surroundwithmdframed[outerlinewidth=0.4pt,
  innerlinewidth=0.5pt,
  middlelinewidth=1pt,
  middlelinecolor=white,
  topline=false,bottomline=false,rightline=false,leftmargin=2em]{prop}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%% Customize Below %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%header stuff
\setlength{\headsep}{24pt}  % space between header and text
\pagestyle{fancy}     % set pagestyle for document
\lhead{General Exam Paper} % put text in header (left side)
\rhead{Nico Courts} % put text in header (right side)
\cfoot{\itshape p. \thepage}
\setlength{\headheight}{15pt}
%\allowdisplaybreaks

% Document-Specific Macros
\newcommand*{\ttc}{{\large $\triangle$}\kern-0.86em\raisebox{0.3ex}{$\scaleobj{0.78}\otimes$}\hspace{1ex}}
\DeclareMathOperator{\Spc}{Spc}

\begin{document}
%make the title page
\title{General Exam Paper \vspace{-1ex}}
\author{Nico Courts}
\date{Winter 2019}
\maketitle

\begin{abstract}
	We begin by going through a considerable amount of domain knowledge concerning representations of $\GL_n$,
	representations of $\frakS_n$, and strict polynomial functors all in service of understanding the Schur-Weyl 
	functor that relates several of these categories. From there, we investigate recent work on the part of Krause 
	and his students Aquilino and Reischuk on this functor and the fact that it is monoidal under reasonably natural monoidal structures on 
	the categories in question. Finally we ask some questions about whether the monoidal structure on strict polynomial functors 
	extends meaningfully to pathologies that arise in positive characteristic.
\end{abstract}

\newpage
\renewcommand{\baselinestretch}{0.75}\normalsize
\setcounter{tocdepth}{3}
\tableofcontents
\renewcommand{\baselinestretch}{1.0}\normalsize

\newpage
\section{Introduction}
\subsection{Issai Schur and polynomial representations}
The story of this project (more-or-less) begins with Schur's doctoral thesis \cite{schur-thesis} in which he defined
polynomial representations of $\GL_n$---a theory which he developed more completely in his later paper \textit{\"Uber die 
rationalen Darstellungen der allgemeinen linearen Gruppe}\footnote{English: \textit{On the rational representations of the general linear group}}
\cite{schur-rational}. In these papers, Schur develops the idea of a \textbf{polynomial representation of $\GL_n$},
meaning a (finite dimensional) representation where the coefficient functions of the representing map 
\[\rho:\GL_n\to \GL(V)\]
is polynomial in each coordinate. For example, the map sending 
\[A=\begin{pmatrix}
	a&b\\
	c&d
\end{pmatrix}\mapsto \begin{pmatrix}
	a^2d-abc & acd-c^2b & 0\\
	abd-b^2c & ad^2-bcd & 0\\
	0 & 0 & ad-bc
\end{pmatrix}=\rho(A)\]
is a three-dimensional polynomial representation of $\GL_2$.

The block-diagonal form above demonstrates a direct sum decomposition of our representation into two parts: one two-dimensional homogeneous degree 3
and one one-dimensional homogeneous degree 2 (in the entries of $A$). A result in \cite{schur-thesis} tells us that, in fact, this can always be done: 
if $V$ is a polynomial representation of $\GL_n$,
then $V$ decomposes as a direct sum of representations 
\[V=\bigoplus_\delta V_\delta\]
where each $V_\delta$ is a polynomial representation where the coefficient functions are \textit{homogeneous degree $\delta$}. 
This allows us to focus our attention to the structure of these $V_\delta$ as the fundamental building blocks of the theory.

The key insight made in this theory comes from the observation that the vector space (recall $V\cong k^n$)
\[E=V^{\otimes r}\]
is made into a $(\GL_n(k),\frakS_r)$-bimodule in a very natural way, and that this bimodule gives us a way to relate 
$\rmod {\frakS_r}$ with (a subcategory of) $\lmod {\GL_n(k)}$ via the so-called \textbf{Schur-Weyl functor.}

\subsection{The Schur-Weyl functor}
Clearly a connection between representations of two groups that are so ubiquitous in group theory and math in general 
is a stunning observation, and much effort has been expended since the late 20th century to study this functor and its 
properties---especially in how it relates the representation theory of these two groups. 

For instance, Friedlander and Suslin \cite{friedlander-suslin}
originally discussed the idea of \textbf{strict polynomial functors} and showed that the category of repesentations 
of the Schur algebra $S(n,d)$ was equivalent to the category $\calP_d$ of homogeneous degree $d$ strict polynomial functors.

In later work, Krause \cite{krause-strict-poly-func} used an alternative construction of $\calP_d$ as the category of
of reprsentations of the $d$-divided powers of the category of finitely generated projective $k$-modules. The upshot being that 
the latter object $\Gamma^d P_k$ has an obvious monoidal structure which $\calP_d$ inherits in a natural way. This new concrete 
monoidal structure opens up the field to discussing several notions of duality defined in different contexts 
and solidifying connections between them.

Krause's students Aquilino and Reischuk, in their paper \cite{aquilino-reischuk}, prove, among other facts, that 
under these natural monoidal structures the Schur-Weyl functor is in fact monoidal. This puts the theory of representations 
of these groups and algebras firmly in the realm of monoidal categories, opening up the area to new questions using 
tools from category theory.

\subsection{Notation and conventions}\label{subsec:notation}
Throughout this paper we will define $k$ to be a field (not necessarily of characteristic zero or algebraically closed unless otherwise noted).
%Let $\Alg_k$ be the category of $k$-algebras and $\Grp$ denote the category of groups with homorphisms.

We will use $\Gamma=\Gamma_k=\GL_n=\GL_n(k)$ to denote the general linear group, $\Aut_k(k^n)$. Let $\frakS_r$ denote the symmetric group on $r$ letters.

When speaking of the ($k$) vector space spanned by elements $v_1,\dots,v_n$, we will use the notation 
\[\langle v_1,\dots, v_n\rangle.\]

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage
\section{Representations of \texorpdfstring{$\Gamma$}{Gamma} and of \texorpdfstring{$\frakS_n$}{Sn}}
We begin by detailing the theory behind the (polynomial) representations of $\GL_n$ as well as the representations of $\frakS_n$ to 
familiarize ourselves with the classical representation theory associated to these groups.

\subsection{Polynomial representations of \texorpdfstring{$\Gamma$}{Gamma}}
Let $\Gamma$ be the affine group scheme defined in section~\ref{subsec:notation}. Then 
\begin{defn}
	A (finite dimensional) \textbf{representation} of $\Gamma$ is a (finite dimensional) vector space $V$ along with a map
	\[\rho:\Gamma\to \GL(V)\eqdef\Aut_k(V)\]
	where $\rho$ is a group homomorphism.
\end{defn}
\begin{rmk}
	Often in representation theory one combines the map $\rho$ and vector space $V$ into a single object:
	a $k\Gamma$-module. This simultaneously encodes the vector space structure (via $k$-linearity) and the action by 
	$\Gamma$.
\end{rmk}
Representations of $\Gamma$ can be, in general, ``analytic.'' One can check that the map 
\[\rho:k^\times=\GL_1(k)\to \GL(k^2)\qquad\text{via}\qquad x\mapsto\begin{pmatrix}
	1 & \ln |x|\\ 0 & 1
\end{pmatrix}\]
gives a group homomorphism (and thus representation) between these two groups, but the logarithm makes this representation decidedly \textit{not algebraic.}
To narrow our focus somewhat and ensure we stay within the realm of algebra, we make the following definition:
\begin{defn}\label{def:poly-rep}
	A \textbf{polynomial representation} of $\Gamma$ is a representation $\rho$ such that the structure maps of $\rho$ 
	are polynomials in the functions $c_{ij}:\Gamma\to k$ that extract the $(i,j)^{th}$ entry.
\end{defn}
\begin{rmk}
	Recall (or learn for the first time!) that the \textit{structure maps} of a representation $(\rho,V)$ are a collection 
	of maps $r_{ij}$ for $1\le i,j,\le n$ from $\Gamma$ to $k$ such that for all $g\in \Gamma$:
	\[g\cdot v_i=\sum_{j=1}^n r_{ij}(g)v_j\]
	where we have picked a basis $\{v_1,\dots,v_n\}$ for $V$. Of course changing basis may change our 
	$r_{ij}$, but an invariant of the representation is the \textbf{span} $\langle r_{ij}\rangle$.
\end{rmk}
\begin{rmk}
	If all $r_{ij}$ are homogeneous polynomials of the same degree, we say that $\rho$ is a \textbf{homogeneous polynomial representation} of $\Gamma$.
\end{rmk}
\begin{defn}\label{def:Mnr}
	Let $M_k(n)=M(n)$ be the collection of all polynomial representations of $\GL_n$ and let $M_k(n,r)=M(n,r)$ 
	be the collection of all degree $r$ polynomial representations of $\GL_n$.

	Generally speaking, we will identify both of these with an appropriate subcategory of $\lmod{k\Gamma}$.
\end{defn}
It is the \textit{polynomial} representations that we will concern ourselves with in the following sections. 

\subsubsection{Reducing scope}
Using some of our familiar friends from representation theory (as well as some clever twists), 
we can simplify this picture considerably by proving the following structural result:
\begin{thm}[{\cite[pp.7-10]{schur-thesis}}]\label{thm:decomp}
	Every polynomial representation $V$ over an infinite field $k$ decomposes as a direct sum 
	\[V\cong\bigoplus_{\delta\in\bbN}V_\delta\]
	where $V_\delta$ is a \textit{homogeneous} polynomial representation of degree $\delta.$
\end{thm}
Clearly, then, it suffices to understand the \textit{homogeneous degree $r$} polynomial representations of $\Gamma$ if we are looking
to understand the larger structure.

\brk

We begin with a useful lemma extracted from a proof in \cite{schur-thesis} echoing the general theory of 
orthogonal decomposition of Artinian algebras.
\begin{lem}\label{lem:orth-decomp}
	Let $C_0,\dots,C_m\in M_n(k)$ be mutually orthogonal idempotent matrices that sum to the identity. That is, 
	\[I_n=\sum_i C_i\quad\text{and}\quad C_iC_j=\delta_{ij}C_i\]
	for all $0\le i,j\le m$. Then there exists an invertible matrix $P$ such that for some positive integers $d_0,\dots,d_m$ with $\sum_k d_k=n$ and for all $i$,
	\[P^{-1}C_iP=\begin{pmatrix}
		\mathbf{0}_{N_i} & &\\
		& I_{d_i} & \\
		& & \mathbf{0}_{M_i}
	\end{pmatrix}\]
	Where $N_i=\sum_{0\le j<i}d_j$ and $M_i=n-d_i-N_i$
\end{lem}
\begin{prf}[of lem~\ref{lem:orth-decomp}]
	We set $S_k=\{C_0,C_1,\dots,C_k\}$ and we proceed by induction on $k$. When $k=0$, $S_k=\{C_0\}$. Now since 
	$C_0^2=C_0$, we get that 1 and 0 are the only eigenvalues of $C_0$, so there is an $r\times r$ matrix $P_0$ 
	and a positive integer $d_0$ such that
	\[P_0^{-1}C_0P_0=\begin{pmatrix}
		I_{d_0} & \\
			& \mathbf{0}_{n-d_0}
	\end{pmatrix}.\]
	which establishes the base case.

	Now assume that we have a matrix $P_{k-1}$ such that this property holds for all elements of $S_{k-1}$.
	Define, for each $0\le i\le k$, 
	\[C_i'\eqdef P^{-1}_{k-1}C_iP_{k-1}\]
	and since the $C_k$ is assumed to be orthogonal to all other $C_i$,
	\[C_k'=\begin{pmatrix}
		\mathbf{0}_{N_k} & \\
		& D_k
	\end{pmatrix}\]
	for some $D_k$.

	Now by properties of block diagonal matrices, we have 
	\[D_k^2=D_k\]
	so the eigenvalues of $D_k$ are again one and zero. Thus there is an invertible $Q\in \GL_{n-N_k}$ such that 
	\[Q^{-1}D_kQ=\begin{pmatrix}I_{d_k} &\\ & \mathbf{0}_{M_k}\end{pmatrix}\]
	and so by setting
	\[P_k\eqdef P_{k-1}\begin{pmatrix}I_{N_k} &\\ & Q\end{pmatrix}\]
	we can define
	\[C''_i\eqdef P_k^{-1}C_i P_k=\begin{pmatrix}I_{N_k} &\\ & Q\end{pmatrix}^{-1}C'\begin{pmatrix}I_{N_k} &\\ & Q\end{pmatrix}\]
	for $0\le i\le k$, we see immediately that $C_i'=C_i''$ for $0\le i<k$ and furthermore 
	\[C_k''=\begin{pmatrix}
		\mathbf{0}_{N_k} & \\
		& Q^{-1}D_kQ
	\end{pmatrix}=\begin{pmatrix}
		\mathbf{0}_{N_k} & &\\
		& I_{d_k} & \\
		& & \mathbf{0}_{M_k}
	\end{pmatrix}\]
	completing the inductive step. This this result holds for all $S_i$ and in particular for $S_m$, so the result is proven.
\end{prf}
As well as another result on a special class of commuting block diagonal matrices:
\begin{lem}\label{lem:block-diag}
	Let $k$ be an infinite field and let $A$ be a block diagonal matrix over $k$ of the form
	\[A=\operatorname{diag}(x^mI_{d_m},x^{m-1}I_{d_{m-1}},\dots,I_{d_0})\]
	where $d_i$ is (clearly) the dimension of the $(m-i)^{th}$ block and let $B$ be any matrix that commutes with $A$
	for every choice of $x\in k$. Then $B$ is block diagonal of the same shape as $A$. 
\end{lem}
\begin{prf}[of lem~\ref{lem:block-diag}]
	We proceed by comparing the entries in $AB$ and $BA$: notice that 
	\[(AB)_{ij}=\sum_k A_{ik}B_{kj}=A_{ii}B_{ij}=x^aB_{ij}\]
	and 
	\[(BA)_{ij}=\sum_k B_{ik}A_{kj}=B_{ij}A_{jj}=x^bB_{ij}.\]
	We will show that if the $(i,j)^{th}$ postion is not in one of the blocks of $A$, then it is zero.

	But if $(i,j)$ is not in one of the blocks of $A$, then the nonzero element in the $i^{th}$ row and the nonzero element in 
	the $j^{th}$ column ($x^a$ and $x^b$ in the above equations) are not the same! Since $x$ is arbitrary, this forces $B_{ij}=0$,
	so $B$ is block diagonal with blocks the same as $A$.
\end{prf}
\begin{rmk}
	Notice that in the above proof we used implicitly that there is an $x\in k$ such that for all $a,b$
	\[x^a=x^b\quad\Rightarrow\quad a=b\]
	which is true if (and only if!) $k$ is infinite. This is because any such $x$ must be a root of $x^n=x$ for some $n$, which 
	has finitely many roots over any field (but every element in $\bbF_p$ satisfies $x^p=x$).
\end{rmk}

And finally using these two lemmas allows us to prove our main result:
\begin{prf}[of thm~\ref{thm:decomp}]
	We recreate the argument in Schur's thesis, translated from German and reinterpreted in more modern parlance. 
	
	Let $(\rho,V)$ be a polynomial representation of $\Gamma$ with $\dim_k V=r$. Then let $x\in k^\times$ be arbitrary (thought of as an indeterminate)
	and consider the matrix $xI_n\in\Gamma$. The image of this matrix under $\rho$ is a matrix 
	\[\rho(A)=\begin{pmatrix}
		p_{11}(x) & \cdots & p_{1r}(x)\\
		\vdots & \ddots & \vdots\\
		p_{r1}(x) & \cdots & p_{rr}(x)
	\end{pmatrix}\]
	where each $p_{ij}$ is a polynomial in $x$. Let $m=\max_{i,j}\deg p_{ij}$, and this gives us a decomposition 
	\[\rho(A)=x^m C_0+x^{m-1}C_1+\cdots+ xC_{m-1}+C_m\]
	where each $C_i$ is an $r\times r$ matrix.

	Let $y$ be another indeterminate and $B=yI_n$. By virtue of being a representation of $\Gamma$, we get 
	\[\rho(A)\rho(B)=\rho(xI_n)\rho(yI_n)=\rho(xyI_n)=\rho(AB)\]
	and using this setup we prove the following result: 
	\[\text{For all $0\le i,j\le m$, with the $C_l$ as above,}\quad C_iC_j=\delta_{ij}C_i\]
	That this is true can be established by comparing coefficients in the equation
	\begin{align*}
		\rho(AB)&=\rho(A)\rho(B)\\
		C_0(xy)^m+\cdots+C_i(xy)^{m-i}+\cdots+C_m&=C_0^2x^my^m+\cdots+C_iC_jx^{m-i}y^{m-j}+\cdots+C_m^2
	\end{align*}
	Indeed, we immediately get that $C_i=C_i^2$ and furthermore the coefficients on $x^iy^j$ when $i\ne j$ give us
	\[0=C_{m-i}C_{m-j}.\]
	
	Thus we have shown that the $C_i$ form a set of orthogonal idempotent matrices and evaluating our original equation at $x=1$,
	we get (since $\rho$ is a homomorphism)
	\[I_r=1C_0+\cdots+1C_m=\sum C_i\]
	so the result from lemma~\ref{lem:orth-decomp} applies: we get a matrix $P$ such that 
	\[P^{-1}\rho(xI_n)P=\begin{pmatrix}
		x^mI_{d_0} & & & &\\
		& x^{m-1}I_{d_1} & & &\\
		& & \ddots & &\\
		& & & xI_{d_{m-1}} & \\
		& & & & I_{d_m}
	\end{pmatrix}\]
	Now let $\rho'(g)=P^{-1}\rho (g)P$ for all $g\in\Gamma$. This is a representation of $\Gamma$ since it it differs from $\rho$ by 
	an automorphism of $\GL(V)$. Since matrix multiplication is an algebraic operation, $\rho'$ is still a polynomial representation of $\Gamma$. 
	But notice that for all $g\in\Gamma$
	\[\rho'(g)\rho'(xI_n)=\rho'(xg)=\rho'(xI_n)\rho'(g)\]
	Then lemma \ref{lem:orth-decomp} gives us that $\rho'(g)$ decomposes in the same way for all $g\in \Gamma$, so 
	we know that $\rho'$ decomposes as a direct sum of representations 
	\[\rho'=\sum_{i=0}^m \rho'_i\]
	where for each $i$ and $\lambda\in k$,
	\[\rho'_i(\lambda g)=\rho_i'(\lambda I_{d_i})\rho_i'(g)=\lambda^i\rho'_i(g)\]
	so each $\rho_i'$ is a homogeneous degree $i$ polynomial representation of $\Gamma$.

	But of course the decomposition of a representation is independent of choice of basis,
	so we get a decomposition of $\rho$ into homogenous pieces, as desired.
\end{prf}

\subsubsection{Monomials and multi-indices}\label{subsubsec:indices}
All of the discussion up to this point has revolved around polynomials in $n^2$ variables, which quickly gets unwieldy unless one 
uses some better notation. To that end, 
\begin{defn}
	An $(n,r)$-\textbf{multi-index} $i$ is an $r$-tuple $(i_1,\dots,i_r)$ where each $i_j\in\underline n\eqdef\{1,\dots,n\}$.
	The collection of all $(n,r)$-multi-indices is denoted $I(n,r)$.
\end{defn}
\begin{rmk}
	One can also think of an element $i\in I(n,r)$ as a (set) map 
	\[i:\underline r\to\underline n.\]
\end{rmk}
The idea here is to associate to each monomial in a polynomial ring in many variables a tuple indicating its multidegree. That is we think of 
\[(i_1,\dots,i_r)\quad\leftrightsquigarrow\quad x_{i_1}\cdots x{i_r}\]
as corresponding to the same object. Which is wonderful except for one small flaw: polynomials are commutative 
and multi-indices (as we have defined them) aren't! For example, in $I(3,4)$,
\[(2,2,1,3)\quad\leftrightsquigarrow\quad x_1x_2^2x_3\quad\leftrightsquigarrow\quad (3,2,1,2).\]

To handle this disparity, we define an equivalence relation on $I(n,r)$ where we say that $i\sim j$ if they are in the 
same orbit under the natural $\frakS_r$ action. That is, if there exists $\sigma\in\frakS_r$ such that
\[(i_1,\dots,i_r)=(j_{\sigma(1)},\dots,j_{\sigma(r)})\]

In the context of polynomial representations of $\Gamma$, we want to consider polynomials in the coordinate functions $c_{ij}$,
so as a matter of notation if $i,j\in I(n,r)$, let $c_{i,j}$ denote the monomial 
\[c_{i,j}=c_{i_1j_1}\cdots c_{i_rj_r}.\]
Again, we want to take into account that we can permute the order on the right hand side, but now we need that $i_k$ and $j_k$ 
remain linked to the same function. To deal with this, we define an equivalence relation $\sim$ on $I(n,r)\times I(n,r)$ such that 
\[(a,b)\sim (c,d)\]
if there exists a $\sigma\in\frakS_r$ such that 
\[(a_1,\dots,a_r)=(b_{\sigma(1)},\dots,b_{\sigma(r)})\quad\text{and}\quad(c_1,\dots,c_r)=(d_{\sigma(1)},\dots,d_{\sigma(r)}).\]
The upshot of this work is that it gives us a bijection between (total) degree $r$ monomials in the $c_{ij}$ and the set
\[I(n,r)\times I(n,r)/\sim\]

\subsubsection{\texorpdfstring{$A_k(n,r)$}{Ak(n,r)}}
Notice that if $V\in M(n,r)$, each of its structure maps are homogeneous degree $r$ polynomials. As the first object of study, consider 
\begin{defn}
	Let $A_k(n,r)=A(n.r)$ denote the collection of all homogeneous degree $r$ polynomials in the 
	coordinate functions $c_{ij}:\Gamma\to k$.
\end{defn}
It is not too hard to see that 
\begin{prop}
	$A_k(n,r)$ is spanned by the elements 
	\[\{c_{i,j}|(i,j)\in I(n,r)\times I(n,r)\}\]
\end{prop}
however it takes a short argument to see 
\begin{lem}
	The dimension of $A_k(n,r)$ over $k$ is $\binom{n^2+r-1}{n^2-1}=\binom{n^2+r-1}{r}$.
\end{lem}
\begin{prf}
	The following is a ``stars and bars'' argument that is pervasive in combinatorics. See for example \cite{stanley} if unfamiliar with these techniques.
	
	Fix an ordering of the $c_{ij}$ (say the dictionary order)
	and relabel them $\{\gamma_1,\dots,\gamma_{m}\}$ (here $m=n^2$) according to this order. Then the degree $r$ monomials are in bijection with $m$-tuples $(a_1,\dots,a_{m})\in\bbN^m$ such that $\sum_i a_i=r$ via the map which sends 
	\[(a_1,\dots,a_{m})\mapsto \gamma_1^{a_1}\cdots\gamma_{m}^{a_{m}}.\]

	But choosing such an element is the same as inserting $m-1$ bars into a line of $r$ stars (that is an ordered partition of $r$ into $m$ parts, 
	where parts are allowed to be zero). But this is equivalent to choosing $m-1$ bars in a field of $m+r-1$ symbols. This is just 
	\[\binom{m+r-1}{m-1}\]
	and a well-known identity for binomial coefficients gets us the final equality.
\end{prf}
\begin{ex}
	In case the reader is unfamiliar with this kind of reasoning, consider the case when $n=5$ and $r=4$. Then the composition $(1,0,0,2,1)$ corresponding to 
	$\gamma_1\gamma_4^2\gamma_5$ corresponds to the stars-and-bars diagram 
	\begin{center}
		$\ast|||\ast\ast|\ast$
	\end{center}
	where there are $m+r-1=8$ symbols, $r=4$ of which are stars.
\end{ex}

\subsubsection{A dip into affine group schemes and category theory}
$A(n,r)$ lies within $k^\Gamma=k(\Gamma)$, the $k$-algebra of functions $\Gamma\to k$, which has the structure of a Hopf algebra induced from the group 
structure on $\Gamma$. More precisely, the functor $\GL_n:\Alg_k\to \Grp$ that assigns to every $k$-algebra $A$ the group $\GL_n(A)$ is representable. In other words, 
\[\GL_n(-)\simeq \Hom_{\Alg_k}(R,-)\]
where $R\cong k[x_{ij}|1\le i,j\le n]_{\det}$.

The anti-equivalence of the categories of affine group schemes over $k$ and finite dimensional commutative $k$-Hopf algebras follows from Yoneda lemma 
(c.f. \cite[chp. 1]{waterhouse}), and along with this equivalence comes a way to translate the group structure on $\Gamma$ 
into a coalgebra structure on $R$: we have maps $\mu,\epsilon$, the multiplication and unit maps on $\Gamma$ satisfying the diagrams 
\begin{center}
	\begin{tikzcd}
		\Gamma\times\Gamma\times\Gamma\ar[r,"\mu\times\id"]\ar[d,"\id\times\mu"] & \Gamma\times\Gamma\ar[d,"\mu"]\\
		\Gamma\times\Gamma\ar[r,"\mu"] & \Gamma
	\end{tikzcd}
	\quad \begin{tikzcd}
		\ast\times G\ar[r,"\epsilon\times\id"] &G\times G\ar[d,"\mu"]& G\times \ast\ar[l,"\id\times\epsilon",swap]\\
		& G\ar[ur,leftrightarrow,"\sim"]\ar[swap,ul,leftrightarrow,"\sim"] &
	\end{tikzcd}
\end{center}
(where $\ast$ is the trivial group) giving us associativity and identity. Yoneda gives us that the maps between functors (group schemes!)
\[\mu:\Gamma\times\Gamma\to \Gamma\quad\text{and}\quad \epsilon:\ast\to\Gamma\]
give rise to maps in $\Alg_k$:
\[\Delta\eqdef\mu^\ast:R\to R\otimes_k R\quad\text{and}\quad \varepsilon\eqdef\epsilon^\ast: R\to k\]
satisfying diagrams 
\begin{center}
	\begin{tikzcd}
		R\otimes R\otimes R & R\otimes R\ar[l,"\Delta\otimes\id",swap]\\
		R\otimes R\ar[u,"\id\otimes \Delta"] & R\ar[u,"\Delta"]\ar[l,"\Delta"]
	\end{tikzcd}
	\quad\begin{tikzcd}
		k\otimes R\ar[dr,"\sim",leftrightarrow,swap] & R\otimes R\ar[l,"\varepsilon\otimes \id",swap]\ar[r,"\id\otimes\varepsilon"] & R\otimes k\ar[dl,"\sim",leftrightarrow]\\
		& R\ar[u,"\Delta"] &
	\end{tikzcd}
\end{center}
\begin{prop}
	The maps $\Delta$ and $\varepsilon$ give $R$ a coalgebra structure. In coordinates, if $1\le i,j\le n$,
	\[\Delta(c_{ij})=\sum_k c_{ik}\otimes c_{kj}\quad\text{and}\quad \varepsilon(c_{ij})=\delta_{ij}\]
\end{prop}
{\color{red} Maybe spell out explicitly how to derive the coalgebra structure through the Yoneda embedding?}

In fact, as mentioned before, $R$ becomes a bialgebra (a Hopf algebra even, although we won't need the antipode here). This means that 
$\Delta$ and $\varepsilon$ are algebra morphisms for the natural algebra structure given by multiplication $m$ on $R$. In diagrams:
\begin{center}
	\begin{tikzcd}
		R^{\otimes 4}\ar[r,"\id\otimes\tau\otimes 1"] & R^{\otimes4}\ar[r,"m\otimes m"]  & R\otimes R\\
		R\otimes R\ar[u,"\Delta\otimes \Delta"]\ar[rr,"m"] & & R\ar[u,"\Delta"]
	\end{tikzcd}
	\quad\begin{tikzcd}
		R\otimes R\ar[r,"m"]\ar[d,"\varepsilon\otimes\varepsilon"] & R\ar[d,"\varepsilon"]\\
		k\otimes k\ar[r,"m"] & k
	\end{tikzcd}
\end{center}
where $\tau:R\otimes R\to R\otimes R$ is the twist map $a\otimes b\mapsto b\otimes a$. 
Chasing an element through the diagram on the left, we get
\[\tilde m\circ (\Delta\otimes \Delta)(c_{ij}\otimes c_{ab})=\sum_{1\le k,l\le n}c_{ik}c_{al}\otimes c_{kj}c_{lb}=\Delta(c_{ij}{c_{ab}})\]
or using our multi-index notation,
\[\Delta(c_{(i,a),(j,b)})=\sum_{(k,l)\in I(n,2)}c_{(i,a),(k,l)}\otimes c_{(k,l),(j,b)}.\]

Written more simply, the fact that $\Delta$ is an algebra morphism can be written 
\[\Delta(a\cdot b)=\Delta(a)\ast\Delta(b)\]
under suitable definitions of $\cdot$ and $\ast$. In a way that can be made precise, this means in particular that 
\[\Delta(a\cdot b\cdot c)=\Delta(a)\ast\Delta(b\cdot c)=\Delta(a)\ast\Delta(b)\ast\Delta(c)\]
and so on (since multiplication everywhere is associative) and therefore we can define this for arbitrary monomials and extend $k$-linearly: 
\begin{prop}
	If $i,j\in A(n,r)$, then 
	\[\Delta(c_{i,j})=\sum_{k\in I(n,r)}c_{i,k}\otimes c_{k,j}\quad\text{and}\quad \varepsilon(c_{i.j})=\delta_{i,j}\]
\end{prop}
One can easily see that degree is preserved by $\Delta$, meaning that 
\begin{prop}
	$\Delta$ and $\varepsilon$ descend to a coalgebra structure on $A(n,r)$. That is, $A(n,r)$ is a ($k$-)coalgebra.
\end{prop}

\subsubsection{The Schur algebra}
Finally we get to the actual object of study:
\begin{defn}
	A \textbf{Schur algebra} is an element of the two-parameter family $\{S(n,r)\}=\{S_k(n,r)\}$ where $n$ and $r$ are any positive integers.
	As a set, $S(n,r)$ is the linear dual of $A(n,r)$:
	\[S(n,r)=A(n,r)^\ast=\Hom_k(A(n,r),k)\] 

	Let $\xi_{i,j}$ denote the element dual to $c_{i.j}\in A(n,r)$. In other words:
	\[\xi_{(a,b)}(c_{i,j})=\begin{cases}
		1, & (a,b)\sim(i,j)\\
		0, & \text{otherwise}
	\end{cases}\]
\end{defn}

\begin{lem}
	The coalgebra structure $(\Delta,\varepsilon)$ on $A(n,r)$ define an algebra structure on $S(n,r)$.
\end{lem}
\begin{prf}
	Since $k$ is an initial object in $\Alg_k$, there is a unique map $u:k\hookrightarrow S(n,r)$ sending $1$ to the unit function $\1$, which is given by 
	\[\1(c_{i,j})=c_{i,j}(I_n)=\delta_{i,j}\]
	Define multiplication $(\cdot)$ in $S(n,r)$ as follows: if $f,g\in S(n,r)$ then for any $x\in A(n,r)$ define 
	\[(f\cdot g)(x)=m_k\circ (f\otimes g)\circ \Delta(x)=\sum f(x_{(1)})g(x_{(2)})\]
	where $m_k:k\otimes k\to k$ denotes multiplication in $k$ and $\Delta(x)=\sum x_{(1)}\otimes x_{(2)}$ in Sweedler notation.

	Then we must just confirm that these maps satisfy the properties of a $k$-algebra. $(\cdot)$ is $k$-bilinear because (for instance)
	\begin{align*}
		((af+bg)\cdot h)(x)&=\sum (af+bg)(x_{(1)})\otimes h(x_{(2)})\\
		&=\sum a(f(x_{(1)})\otimes h(x_{(2)}))+b(g(x_{(1)})\otimes h(x_{(2)}))\\
		&= a\sum f(x_{(1)})\otimes h(x_{(2)})+ b\sum g(x_{(1)})\otimes h(x_{(2)})\\
		&=(a(f\cdot h)+b(g\cdot h))(x).
	\end{align*}
	
	By $k$-linearity, it suffices to show that the unit $\1$ acts as it should on the spanning set $\xi_{i,j}$ for a basis element $c_{a,b}$:
	\[(\1\cdot \xi_{i,j})(c_{a,b})=\sum_{k=1}^n \1(c_{a,k})\cdot\xi_{i,j}=\1(c_{a,a})\cdot\xi_{i,j}(c_{a,b})=\xi_{i,j}(c_{a,b})\]
	and a similar identity holds on the right.

	Then it remains to show that this multiplication is associative. Again by linearity it suffices to check that this works on the spanning set $\{c_{i,j}\}$:
	\begin{align*}
		((\alpha\cdot \beta)\cdot\gamma)(c_{i,j})&=\sum_{k\in I(n,r)}(\alpha\cdot\beta)(c_{i,k})\gamma(c_{k,j})\\
		&=\sum_k\left(\sum_{l\in I(n,r)}\alpha(c_{i,l})\beta(c_{l,k})\right)\gamma(c_{k,j})\\
		&=\sum_l\alpha(c_{i,l})\left(\sum_k \beta(c_{l,k})\gamma(c_{k,j})\right)\\
		&=\sum_l\alpha(c_{i,l})(\beta\cdot\gamma)(c_{l,j})\\
		&=(\alpha\cdot(\beta\cdot\gamma))(c_{i,j}).
	\end{align*}

	Thus since we have $k$-linear maps $\1$ and $m=(\cdot)$ satisfying the usual identity and associativity diagrams, $S(n,k)$ is a $k$-algebra 
	with $\1$ and $m$ as its unit and multiplication.
\end{prf}

Why have we done all this work to construct Schur algebras, one may ask? Well the idea is that there is a map
\[e:k\Gamma\to S(n,r)\]
where it sends 
\[\sum_i k_i g_i\mapsto \sum_i k_i e_{g_i}\]
where $e_g$ is the ``evaluation at $g$'' map--that is, for all $x\in A(n,r)$,
\[e_g(x)=x(g).\]
\begin{lem}\label{lem:e-surj}
	The map $e:k\Gamma\to S(n,r)$ is surjective.
\end{lem}
\begin{prf}
	Let $\xi$ be any element orthogonal to $W=\Im e$, if one exists. Say this element is $\sum_{i,j}a_{i,j}\xi_{i,j}$.
	But then the element $c=\sum a_{i,j}c_{i,j}$ is zero on every element in the image of $e$. In other words, for all $\kappa\in k\Gamma$,
	\[c(\kappa)=e_\kappa(c)=0.\]
	
	But the only function in $k^\Gamma$ that is zero on all of $\Gamma$ is the zero function. Thus $\xi$ is zero, so $W=S(n,r)$
\end{prf}

In this way, $e$ induces a map between categories
\[f:\lmod{S_k(n,r)}\to M_k(n,r)\]
where $f(V)=V$ as far as underlying sets are concerned, but we are given a new action: 
for any $\sum k_i g_i\in k\Gamma$ and $c\in V\in \lmod{S(n,r)}$,
\[\left(\sum k_i g_i\right)\cdot v=\left(\sum k_i e_{g_i}\right)\cdot v.\]
Notice that 
\begin{lem}
	$f$ as above defines a functor that sends any $\alpha:V\to W\in \lmod{S(n,r)}$
	to the map that is identical as a map of sets. 
\end{lem}
\begin{prf}
	Since we are working in a concrete category\footnote{There is a faithful functor to $\Set$; equivalently, any morphism is determined by where it sends the ``set of elements'' comprising the object.}, 
	and since the $V$ and $f(V)$ are identical as sets and since any morphism is sent to the same map on underlying sets, commutativity of 
	the functorality diagram 
	\begin{center}
		\begin{tikzcd}
			V\ar[r,"\alpha"]\ar[d,"f"] & W\ar[d,"f"]\\
			f(V)=V\ar[r,"f(\alpha)=\alpha"] & f(W)=W
		\end{tikzcd}
	\end{center}
	is trivial to check. It remains only to check that $f(\alpha):V\to W$ is a morphism in $M(n,r)$, so that this diagram makes sense.

	To check this, notice that for any $v\in V\in M(n,r)$ and $g\in k\Gamma$,
	\[f(\alpha)(g\cdot v)=\alpha(e_g\cdot v)=e_g\cdot \alpha(v)=g\cdot f(\alpha)(v)\]
	so $f$ is a functor.
\end{prf}
The upshot here is 
\begin{thm}
	The functor $f$ above is an equivalence of categories.
\end{thm}
\begin{prf}
	That $f$ is faithful is easy enough to see since $f$ is the identity functor on the level of underlying sets. Let $g:V\to W$ be a morphism in 
	$M(n,r)$ and consider the same (set) map in $\tilde g\in\lmod{S(n,r)}$. For any $\xi\in S(n,r)$, let $\kappa\in k\Gamma$ be an element such that $e_\kappa=\xi$
	(which exists due to lem~\ref{lem:e-surj}).
	Then 
	\[\tilde g(\xi\cdot v)=g(\kappa\cdot v)=\kappa\cdot g(v)=\xi\cdot \tilde g(v)\]
	But then $f(\tilde g)=g$, so $f$ is full.

	It remains to see that $f$ is essentially surjective. But again this is not too hard to see since for any $V\in M(n,r)$ the same object setwise with the action given by 
	\[\xi\cdot v=e_\kappa\cdot v\]
	(where again $\kappa$ was chosen using lem~\ref{lem:e-surj}) maps to $V\in M(n,r)$ and we are done.
\end{prf}
\begin{rmk}
	Actually, the above proof can be modified slightly to show that $f$ has a functorial inverse--that is, $f$ is an \textit{isomorphism of categories}.
	Since we are only interested in representations up to isomorphism, however, equivalence is just as good.
\end{rmk}
\begin{rmk}
	Using this equivalence, we identify $\lmod{S(n,r)}$ with $M(n,r)$ whenever it suits us.
\end{rmk}

One of a representation theorist's favorite kinds of results follows:
\begin{cor}
	If $\ch k=0$, the algebra $S(n,r)$ is semisimple.
\end{cor}
\begin{prf}
	$k\Gamma$ is semisimple since $\ch k=0$, so every element in $\lmod{k\Gamma}$ splits into a direct sum of simple modules. But the irreducible objects in 
	$M(n,r)$ and those in $\lmod{S(n,r)}$ are the same and decompositons in one category pull back to the other, so every element in $\lmod{S(n,k)}$ is also completely reducible.
\end{prf}

\subsubsection{Weights and characters}
The discussion in section~\ref{subsubsec:indices} highlights an important idea: while we care about the \textit{quantities} in which each $c_{ij}$ occurs 
in a monomial, we are not particularly interested in the \textit{order}. Sometimes it is easier, then, to simply regard these as weak compositions:
\begin{defn}
	Let $n$ and $r$ be integers as usual. Then denote by $[a_1,\dots,a_n]$ the \textbf{weight} corresponding to 
	$(i_1,\dots,i_r)\in I(n,r)$ where for each $i$,
	\[a_i=\#\{k\in\underline r| i_k=i\}\]
	Denote by $\Lambda(n,r)$ the collection of all weights. 
\end{defn}
\begin{rmk}
	Another way to realize $\Lambda(n,r)$ is in the presentation 
	\[\Lambda(n,r)=\left\{[a_1,\dots,a_n]\left|\sum_i a_i=r\right.\right\}\]
	Yet another is to think of $\Lambda(n,r)$ as the set of $\frakS_r$ orbits in $I(n,r)$ (where now two objects 
	are distinguished only if their ``contents'' vary).
\end{rmk}
Recall that we had that $\xi_{i,j}(c_{a,b})=1$ if and only if $(i,j)\sim(a,b)$. Because of this, it makes sense (if $\alpha$ is the 
weight of $i$) to write 
\[\xi_{\alpha}\eqdef \xi_{\alpha,\alpha}\eqdef \xi_{i,i}\]
since the action is the same irrespective of the choice of representative $i$ of $\alpha.$

Notice that the weights admit a $\frakS_n$ action 
\[\sigma\cdot [a_1,\dots,a_n]=[a_{\sigma(1)},\dots,a_{\sigma(n)}]\]
then 
\begin{defn}
	$\Lambda_+(n,r)$ is the orbit space of $\Lambda(n,r)$ under the above $\frakS(n)$ action.
\end{defn}
\begin{rmk}
	The above are called the \textbf{dominant weights} in $M(n,r)$. Since each orbit $\alpha$ contains an element $[a_1,\dots,a_n]\in\alpha$ such that 
	\[a_1\ge a_2\ge\cdots\ge a_n\]
	we will often identify weights with their weakly-decreasing representative.

	Sometimes we will refer to the dominant weight representing the orbit of $i\in I(n,r)$ as the \textbf{shape of $i$.}
\end{rmk}

The theory of weights in representations of $\Gamma$ closely mirrors similar decompositions in other 
Artinian algebras: first we identify a family of (mutually orthogonal) idempotents:
\begin{lem}
	For $\alpha\in\Lambda(n,r)$ and $i,j\in I(n,r)$,
	\[\xi_\alpha\xi_{i,j}=\begin{cases}
		\xi_{i,j}, & i\in\alpha\\
		0, &\text{otherwise}
	\end{cases}\quad\text{and}\quad\xi_{i,j}\xi_\alpha=\begin{cases}
		\xi_{i,j}, & j\in\alpha\\
		0, &\text{otherwise}
	\end{cases}\]
\end{lem}
\begin{prf}
	We can compute the image of these on the $c_{a,b}\in A(n,r)$:
	\begin{align*}
		\xi_\alpha\cdot \xi_{i,j}(c_{a,b})&=\sum_k \xi_\alpha(c_{a,k})\xi_{i,j}(c_{k,b})\\
		&= \xi_\alpha(c_{a,a})\xi_{i,j}(c_{a,b})
	\end{align*}
	where above we used that $\xi_{\alpha}(c_{i,j})=0$ unless $i=j$. But 
	\[\xi_\alpha(c_{a,a})=\begin{cases}
		1, & a\in\alpha\\ 0, & \text{otherwise}
	\end{cases}\]
	so 
	\[\xi_\alpha\cdot \xi_{i,j}(c_{a,b})=\begin{cases}
		\xi_{i,j}(c_{a,b}),& a\in\alpha\\ 0,& \text{otherwise}
	\end{cases}\]
	but in the case where $a\in\alpha$ and $\xi_{i,j}(c_{a,b})\ne 0$, this implies that $i\sim a$, so $i\in \alpha$. So finally,
	\[\xi_\alpha\cdot \xi_{i,j}(c_{a,b})=\begin{cases}
		\xi_{i,j}(c_{a,b}),& i\in\alpha\\ 0,& \text{otherwise}
	\end{cases}\]
	and since this holds for any $c_{a,b}$, the left-hand side is proven. A symmetric argument goes through for the right-hand side.
\end{prf}

For the next step, we decompose the identity into a sum of these idempotents:
\begin{lem}\label{lem:decomp-one}
	We have the decomposition 
	\[\1 = \sum_{\alpha\in\lambda(n,r)} \xi_\alpha.\]
\end{lem}
\begin{prf}
	On the one hand, for any $c_{a,b}\in A(n,r)$, $\1(c_{a,b})=\delta_{a,b}$. On the other hand, for any $\alpha$,
	\[\xi_\alpha(c_{a,b})=0\]
	when $a\ne b$ \textit{or when $a\notin \alpha$}. 
	
	Therefore when $a=b$, there is precisely one $\alpha$ (the orbit of $a=b$)
	such that $\xi_\alpha(c_{a,b})=1$, so putting this all together,
	\[\sum_{\alpha\in\Lambda(n,r)}\xi_\alpha(c_{a,b})=\delta_{a,b}\]
	whence these two functions are equal.
\end{prf}
\begin{rmk}\label{rmk-weight-spaces}
Using lemma~\ref{lem:decomp-one}, we can then decompose any $V\in M(n,r)$ into weight spaces:
\[V=\1\cdot V=\sum_{\alpha\in\Lambda(n,r)}\xi_\alpha V\]
which we will denote 
\[\xi_\alpha V=V^\alpha.\]
\end{rmk}

\begin{defn}
	The \textbf{formal character} of a representation $V\in M(n,r)$ is a polynomial 
	\[\Phi_V(X_1,\dots,X_n)=\sum_{\alpha\in\Lambda(n,r)}(\dim V^\alpha)X_1^{\alpha_1}\cdots X_n^{\alpha_n}=\sum_{\lambda\in\Lambda_+(n,r)}(\dim V^\alpha)m_\alpha(X_1,\dots,X_n)\]
	where $m_\alpha$ is the \textit{monomial symmetric polynomial}
	\[m_\alpha(X_1,\dots,X_n)=\sum_{\sigma\in\frakS_n}X_{\sigma(1)}^{\alpha_1}\cdots X_{\sigma(n)}^{\alpha_n}.\]
\end{defn}

\subsubsection{Irreducible representations}
The irreducible representations in $M(n,r)$ are given by a couple of results by some of the big names in representation theory: the original proof for $k=\bbC$ was proven in \cite[p.37]{schur-thesis} and then 
generalized in a later paper by Weyl \cite{weyl} and in work by Chevalley\footnote{Green \cite{green} mentions a paper by Serre: \textit{Groupes de Grothendieck des Sch\'emas en Groupes R\'eductifs D\'eploy\'es} \cite{serre-chevalley}, which 
makes mention to Chevalley's contributions in proving the existence of modules with prescribed characters.}:
\begin{thm}
	Fix the usual lexicographical ordering on monomials in $k[X_1,\dots,X_n]$. Let $n$ and $r$ be given integers with $n\ge 1$ and $r\ge 0$ Let $k$ be an infinite field. Then 
	\begin{enumerate}
		\item For each $\lambda\in\Lambda_+(n,r)$, there exists an (absolutely) irreducible module $F_{\lambda,k}$
		in $M_k(n,r)$ whose character $\Phi_{\lambda,k}$ has leading term $X_1^{\lambda_1}\cdots X_n^{\lambda_n}$.
		\item Every irreducible $V\in M_k(n,r)$ is isomorphic to $F_{\lambda,k}$ for exactly one $\lambda\in \Lambda_+(n,r)$.
	\end{enumerate}
\end{thm}
So then the problem of classifying the simple modules (the ``basic building blocks'' in the semisimple case) is completely solved for infinite fields.
It remains to demonstrate a way to construct $F_{\lambda,k}$.
\begin{defn}
	Fix some $\lambda\in \Lambda_+(n,r)$. Notice that this corresponds to a Young diagram with $r$ boxes. Fix any labeling $1,\dots,r$ of the boxes in the 
	Young diagram corresponding to $\lambda$. Let $T$ denote the diagram for $\lambda$ along with this labeling.
	
	Let $i:\underline r\to\underline n$ be any map. Then denote by $T_i$ the \textbf{$\lambda$-tableau}, which is $T$ with the $k^{th}$ entry consisting of $i(k)\in\underline r$.
\end{defn}
\begin{rmk}
	This notation varies slightly (but not in spirit) from the notation in Green's book. He denotes the Young diagram by $[\lambda]$ and lets $T^\lambda$ be 
	the labelling of the boxes in $[\lambda]$--a bijection $[\lambda]\to\underline r$.
\end{rmk}
\begin{ex}
	Let $\lambda=(3,1,1)\in\Lambda_+(3,5)$. Thus $T$ is of shape 
	\[\ytableausetup{smalltableaux,centertableaux}\ydiagram{3,1,1}\]
	Then if we fix the left-to-right/top-to-bottom ordering of the boxes in $T$ and let $i:\{1,2,3,4,5\}\to\{1,2,3\}$
	be given by $(2,1,3,3,2)$, we get the $\lambda$-tableau 
	\[T_i=\ytableaushort{2 1 3, 3, 2}\]
\end{ex}

The core tool in constructing (a basis for) the irreducible modules is in the following definiton:
\begin{defn}
	Let $\lambda\in\Lambda_+(n,r)$ be some shape with a fixed labeling and let $i,j:\underline r\to\underline n$. Then the \textbf{bideterminant of $T_i$ and $T_j$}
	is 
	\[(T_i:T_j)=\sum_{\sigma\in C(T)}\operatorname{sgn}(\sigma)c_{i,j\sigma}\in A_k(n,r)\]
	where $C(T)$ is the column stabilizer of $T$.
\end{defn}
This definition can be a bit difficult to unpack, so we give some examples:
\begin{ex}
	\begin{enumerate}
		\item $\lambda=(2,1,0)\in \Lambda_+(3,3)$\[\ytableausetup{nosmalltableaux}\left(\ytableaushort{1 2,3}:\ytableaushort{3 1,2}\right)=\left|\begin{array}{cc}
			c_{13} & c_{12}\\ c_{33} & c_{32}
		\end{array}\right|c_{21}=(c_{13}c_{32}-c_{12}c_{33})c_{2,1}=c_{(1,2,3),(3,1,2)}-c_{(1,2,3),(2,1,3)}\]
		\item $\lambda=(n,0,\dots,0)\in\Lambda_+(m,n)$\[\left(\begin{ytableau} a_1& a_2& a_3&\none[\dots] &a_n\end{ytableau}:
		\begin{ytableau} b_1& b_2& b_3&\none[\dots]&b_n\end{ytableau}\right)=c_{a_1b_1}\cdots c_{a_nb_n}\]
		\item $\lambda=(1,\dots,1,0,\dots)\in\Lambda_+(m,n)$ where $n\ge m$ \[\left(\begin{ytableau}a_1\\ a_2\\\none[\vdots]\\a_n\end{ytableau}:\begin{ytableau}b_1\\ b_2\\\none[\vdots]\\b_n\end{ytableau}\right)=
			\left|\begin{array}{ccc}c_{a_1b_1} & \cdots & c_{a_1b_n}\\
			\vdots & \ddots & \vdots\\
			c_{a_nb_1} & \cdots & c_{a_nb_n}
			\end{array}\right|\]
	\end{enumerate}
\end{ex}

In the following, let $l:\underline r\to\underline n$ be $(1,\dots,1,2,\dots,2,3,\dots)$ such that for any shape $\lambda$ the 
$\lambda$-tableau $T_l$ is 
\[\begin{ytableau}
	1 & 1 &\none[\dots] &\none[\dots] &1\\
	2 & 2 &\none[\dots] &2\\
	\none[\vdots]\\
	k
\end{ytableau}\ytableausetup{smalltableaux}\]
with $i$ in every box on the $i^{th}$ row from the top.

{\color{red} Need to finish constructing the $D_{\lambda,k}$ and $V_{\lambda,k}$ here so we have tangible irreducibles.}


\subsection{Representations of \texorpdfstring{$\frakS_n$}{Sn}}
{\color{red}Spell out the basics of the representation theory for $\frakS_n$ over $\bbC$. Fulton and Harris is a good reference here.}

\subsection{Explicit Examples}
To demonstrate the theory developed above, we begin a computation (in a simple case) of the isomorphism classes of irreducible 
representations of both $S_\bbC(2,2)$ and $\frakS_2$.

\subsubsection{The symmetric group on two letters}
The representation theory (over $k=\bbC$) of $\frakS_2$ is as simple as it comes: of course $\frakS_2\cong \bbZ/2\bbZ$ and we know that 
there are $|G|$ nonisomorphic irreducible representations of an abelian group $G$ over $\bbC$. Since we are talking about a symmetric group, 
we can realize these as the trivial and sign representations, represented by the Young diagrams:
\[\ydiagram{2}\quad\text{and}\quad\ydiagram{1,1}\]

As submodules of the regular representation $k\frakS_2= k e\oplus k(1\,2)$, we can construct these as $\langle e+(1\, 2)\rangle$ (trivial representation) and $\langle e-(1\,2)\rangle$ (sign representation).

\subsubsection{The Schur algebra \texorpdfstring{$S_\bbC(2,2)$}{S(2,2)}}
Since $\ch\bbC=0$, (by e.g. \cite{schur-thesis}) we know immediately that $S_\bbC(2,2)$ is semisimple, so it suffices to identify the irreducible submodules therein.
Now we know 
\[S=S_\bbC(2,2)\cong \bbC^2\otimes\bbC^2\]
so $\dim_\bbC S=4.$ The theory outlined above give us that isomorphism types of irreducible modules are in bijection with compositions of 2 of length 2, meaning 
we have two isomorphism types: one corresponding to $\lambda_1=(1,1)$ and one corresponding to $\lambda_2=(2,1)$. 

Using the construction of $D_{\lambda,\bbC}$ from above, we can compute these two irreducible modules explicitly:

\begin{ex}[$\mathbf{\lambda_1=(1,1)}$]
 In this case our shape is $(1,1)$, corresponding to the Young diagram 
\[\ydiagram{1,1}\]
and then $D_{\lambda_1,\bbC}$ is spanned by the element
\[(T_l:T_{(2,1)})=\left(\ytableaushort{1,2}:\ytableaushort{2,1}\right)=c_{12}c_{21}-c_{11}c_{22}=c_{(1,2),(2,1)}-c_{(1,2),(1,2)}\in A_\bbC(2,2)\]
since all other bideterminants of this shape are zero or linearly dependent. Thus this is a one-dimensional irreducible representation.
\end{ex}
\begin{ex}[$\mathbf{\lambda_2=(2,0)}$]
Now our shape is $(2,0)$, corresponding to the diagram
\[\ydiagram{2}.\]
The bideterminants here are 
\begin{align*}
	(T_l:T_{(1,1)})=\big(\ytableaushort{1 1}:\ytableaushort{1 1}\big)=c_{11}^2\\
	(T_l:T_{(1,2)})=(T_l:T_{(2,1)})=c_{11}c_{12}\\
	(T_l:T_{(2,2)})=c_{12}^2
\end{align*}
So we have a three-dimensional irreducible representation spanned by $\langle c_{11}^2,c_{11}c_{12},c_{12}^2\rangle$.
\end{ex}
Since these are the only two Young diagrams of size two, these examples form a complete list of isomorphism classes of irreducible representations of $S_\bbC(2,2)$.

If we prefer instead to recognize our irreducibles as submodules of $E^{\otimes 2}$ (giving us a more obvious action by our algebras), 
we can use the short exact sequence 
\[0\to N\hookrightarrow E^{\otimes 2}\twoheadrightarrow D_{\lambda,\bbC}\to 0\]
to define the $N=\ker\pi$, where $\pi$ is defined to be the map taking 
\[e_i\otimes e_j\mapsto (T_{(1,1)}:T_{(i,j)}).\] 
Then we can compute the orthogonal complement to $N$ to get $V_{\lambda,\bbC}$.
We can compute:
\[V_{\lambda_1,\bbC}=\langle e_1\otimes e_2-e_2\otimes e_1\rangle\]
and
\[V_{\lambda_2,\bbC}=\langle e_1\otimes e_1, \,e_1\otimes e_2+e_2\otimes e_1, \,e_2\otimes e_2\rangle\]
where $\{e_1,e_2\}$ is a basis for $E\cong k^2$.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\newpage
\section{The Schur-Weyl Functor}
From the discussion in the last section it is evident that the combinatorics behind the representation theory of $S(n,r)$ and $\frakS_r$ have some intersections
in their use of Young tableaux and this connection is more than superficial. In fact, there is a functor relating the representations
of these two objects in the following way:
\subsection{Construction of the functor \texorpdfstring{$\calF$}{F}}

Let $V\in M_k(n,r)$ be a $S(n,r)$-representation and select any weight $\alpha\in\Lambda(n,r)$. Then the weight space (cf. rmk~\ref{rmk-weight-spaces})
\[V^\alpha=\xi_\alpha V\]
becomes a $S(\alpha)\eqdef\xi_\alpha S(n,r)\xi_\alpha$-module using the action from $S(n,r)$. Now if we allow $r\le n$ and let
\[\omega=(1,\dots,1,0,\dots,0)\in\Lambda(n,r)\]
notice that $S(\omega)$ is spanned by the elements
\[\xi_\omega\xi_{i,j}\xi_\omega,\quad i,j\in I(n,r)\]
but by the multiplication rules established in the definition of $S(n,r)$, these are nonzero precisely when 
$i$ and $j$ are both of shape $\omega$. So then since $\xi_{i,j}=\xi_{i\sigma,j\sigma}$ for all $\sigma\in\frakS_r$, we can take as
a basis of $S(\omega)$ the set 
\[\{\xi_{u\pi,u}|\pi\in\frakS_r\}\]
where $u=(1,2,\cdots,r)\in I(n,r)$.

To prove the next statement we require a computational result.
\begin{lem}\label{lem:somega-mult}
	If $u=(1,2,\dots,r)\in I(n,r)$, then for all $\pi,\sigma\in\frakS_r$,
	\[\xi_{u\pi,u}\cdot \xi_{u\sigma,u}=\xi_{u\pi\sigma,u}.\]
\end{lem}
\begin{prf}
	Using the formulas for multiplication in $S(n,r)$, recall that 
	\begin{equation}
		\xi_{u\pi,u}\cdot\xi_{u\sigma,u}=\sum Z_{i,j} \xi_{i,j}\label{eq:1}
	\end{equation}
	where 
	\[Z_{i,j}=\#\{s\in I(n,r)|(u\pi,u)\sim(i,s)\text{ and }(u\sigma,u)\sim (s,j)\}.\]
	Then for each $i,j$, since $u=(1,2,\dots,r)$ has no stabilizer in $\frakS_r$, there is a unique 
	$g$ such that $u\pi g=i$, meaning that $s=ug$. 

	But then this fixes (again a unique) $h\in\frakS_r$ such that $u\sigma h=s=u g$ whence $\sigma h= g$. 
	One computes that 
	\[u\pi\sigma h = u\pi g=i\quad\text{and}\quad uh = j\]
	therefore since in the above computation $s$ was completely determined by $i$, we have
	\[Z_{i,j}=\left\{\begin{array}{lr}
		1, &  (i,j)\sim(u\pi\sigma,u)\\
		0, & \text{otherwise}
	\end{array}\right.\]
	and the result follows.
\end{prf}
Using this result, we prove a more obviously useful statement:

\begin{lem}
	$S(\omega)\cong k\frakS(r)$.
\end{lem}
\begin{prf}
	Define the map $\varphi:S(\omega)\to k\frakS_r$ on the basis above to be 
	\[\varphi (\xi_{u\pi,u})=\pi\]
	and extending $k$-linearly.

	This is a homomorphism since 
	\[\varphi(\xi_{u\pi,u}\xi_{u\sigma,u})=\varphi(\xi_{u\pi\sigma,u})=\pi\sigma=\varphi(\xi_{u\pi,u})\varphi(\xi_{u\sigma,u})\]
	and it is bijective since it is bijective on the respective bases and is thus bijective as a linear map.
\end{prf}
The upshot of these lemmas is that one can define the \textbf{Schur-Weyl functor} 
\[\calF:M_k(n,r)\to \Rep(\frakS_r)\]
via the map that sends any representation $V$ to its $\omega$ weight space $V^\omega\in \lmod {S(\omega)}\simeq \Rep(\frakS_r)$.

\subsection{The general theory}
The idea of the Schur functor fits into a larger context: Let $S$ be a $k$-algebra and let $M\in\lmod S$. Furthermore, let $e\in S$ be a (nonzero)
idempotent. Then one can define a functor 
\[\calF:\lmod S\to\lmod {eSe}\quad\text{via}\quad V\mapsto eV.\]
An important property of this functor is 
\begin{prop}\label{prop:F-irred}
	The image of an irreducible $S$ module under the functor $\calF$ above is zero or irreducible.
\end{prop}
\begin{prf}
	Let $e\in S$ be the idempotent in the discussion above and let $W\subseteq eV$ be any nonzero $eSe$-submodule.
	Then notice that $eW$ is a nonzero $S$-module contained in $e^2V=eV$, so $eW=eV$.
	But since $eW\subseteq W$, this forces $W=eV$, so $\calF(V)$ is irreducible.
\end{prf}

Next, a discussion in Green \cite[p. 56]{green} gives us a natural thought process to follow in constructing a partial inverse to this functor. 
Let $\calG:\lmod{eSe}\to\lmod S$ be an extension of scalars: specifically, if $M\in\lmod{eSe}$, then 
\[\tilde\calG(M)=Se\otimes_{eSe}M.\]
This is clearly functorial and furthermore satisfies the property that 
\[\calF\circ\tilde\calG(M)=\calF(Se\otimes_{eSe}M)=e(Se\otimes_{eSe}M)=eSe\otimes_{eSe} M\cong e\otimes_{eSe}M\cong M\]
so it is a right inverse (up to isomorphism) to $\calF$---a good candidate for our purposes. 
\begin{rmk}
	It is easy to prove the fact, which I glossed over above, that $M\cong e\otimes M$ via the $eSe$-isomorphism $m\mapsto e\otimes m$.
\end{rmk}

What we are really looking for, however, is a functor that sends irreducible modules to irreducibles. It can be shown that $\tilde G$ 
\textit{does not} satisfy this property, so we define 
\begin{defn}
	If $M\in\lmod S$ and $e\in S$ is an idempotent, denote by $M_{(e)}$ the largest $S$-submodule of $(1-e)M$.
\end{defn}
\noindent which enables us to define the functor 
\[\calG:\lmod{eSe}\to \lmod S\quad\text{via}\quad M\mapsto \tilde\calG(M)/\tilde\calG(M)_{(e)}.\]
This leads to the result:
\begin{prop}
	If $M\in \lmod{eSe}$ is irreducible, then so is $\calG(M)$.
\end{prop}
\begin{prf}
	Let $W$ be an $S$-module such that 
	\[\tilde\calG(M)_{(e)}\subseteq W\subseteq \tilde\calG(M)\]
	Then consider multiplying by $e$ in the above inculsions:
	we get
	\[0=e\tilde\calG(M)_{(e)}\subseteq eW\subseteq e\tilde \calG(M)=\calF\circ\tilde\calG(M)\simeq M\]
	which, by the irreducibility of $M$, forces either $eW=0$ (in which case $W\subseteq\tilde\calG(M)_{(e)}$ and we are done)
	or else $eW=e\tilde\calG(M)$.

	In this latter case, we find 
	\[\tilde\calG(M)= Se\otimes M\simeq Se\otimes eSeM=S(eSe\otimes M)=S(e\tilde\calG(M))=SeW\subseteq W\]
	Thus we can conclude that $W=\tilde\calG(M)$, so $\calG(M)$ has no nontrivial proper submodules, so it is simple.
\end{prf}

\subsection{Properties of \texorpdfstring{$\calF$ and $\calG$}{F and G}}
Returning to the specific case of $S=S(n,r)$ and $eSe\cong\frakS_r$, the theory developed in the last part
gives us a pair of functors
\[\calF:M(n,r)\to \lmod{\frakS_r},\qquad \calG:\lmod{\frakS_r}\to M(n,r),\]
each of which preserve irreducibility. We also have that
\begin{prop}
	If $M\in M(n,r)$ is irredicible and if $eM\ne 0$, then $\calG\circ\calF(M)=\calG(eM)\cong M.$
\end{prop}
\begin{prf}
	Notice by prop.~\ref{prop:F-irred} and the following discussion that $eM$ is irreducible and (by assumption) nonzero, so
	\[\calF\circ\calG(eM)\cong eM\]
	and since 
	\[0\ne eM\subseteq M\]
	and $M$ is irreducible, $eM=M$.
\end{prf}
This leads us to the following realization:
\begin{cor}
	If $\{M_\alpha\}_{\alpha\in\calI}$ is a complete collection of irreducible modules over $S(n,r)$,
	then there exists a subset $\calJ\subseteq\calI$ such that $\{\calF(M_\alpha)\}_{\alpha\in\calJ}$
	is a complete (and irredunant) set of irreducible $\frakS_r$-modules.

	Furthermore, any index $j\in\calJ$ satisfies $\calG\circ\calF(M_j)\cong M_j$.
\end{cor}

{\color{red} To add: prove that these are honest adjoints.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Strict polynomial functors}
The theory of strict polynomial functors has its genesis in the idea of \textit{polynomial maps between vector spaces},
or equivalently the rational maps between the schemes they represent. The category of vector spaces with these polynomial maps---and 
more specifically, the representaion category associated to it---gives the category $\Rep \Gamma^d_k$ of strict polynomial functors. 

Originally definied by Friedlander and Suslin in \cite{friedlander-suslin}, the authors there showed that 
the category $\lmod{S(n,r)}$ is equivalent to this category, introducing the language of polynomial functors as 
a way to understand the structure of representations of the Schur algebras. 

This process was carried out by Krause \cite{krause-strict-poly-func} and his students Aquilino and Reischuk \cite{aquilino-reischuk}.
In the former, Krause identifies projective generators $\Gamma^{d,V}$ for $\Rep\Gamma^d_k$ and defines the tensor product 
by defining it for projectives and taking the appropriate colimits. In the latter paper, the construction 
is further elucidated and it is proven that the Schur-Weyl functor $\calF$ is monoidal.

\subsection{Polynomial maps}
Let $V,W$ be vector spaces over a field $k$. There are many equivalent formulations of polynomial maps between such spaces, 
but one that this author of this paper finds particulaly motivating is the following:
\begin{defn}\label{defn:poly-maps}
	Let $V,W$ be as above. Then the set of \textbf{polynomial maps from $V$ to $W$} is defined to be 
	\[\Hom_\text{Pol}(V,W)\eqdef \Hom_{\Sch/k}(V,W).\]
\end{defn}

To make sense of this definition, one recalls that every $V\in\Vectk$ corresponds to an affine $k$-scheme 
$\Spec S^\ast(V^\vee)=V\otimes_k-$ (which we, through an abuse of notation, again denote $V$) represented by the symmetric algebra of the dual of $V$. Thus the polynomial maps
are precisely the rational maps one considers between these objects in their algebro-geometric realizations.

\begin{rmk}
	In Friedlander and Suslin's original paper, they define these maps abstractly as $S^\ast(V^\vee)\otimes W$. That this 
	agrees with our definition (assuming that $V$ and $W$ are finite dimensional) follows from the following series of isomorphisms:
	\begin{align*}
		\Hom_\text{Pol}(V,W)&\eqdef\Hom_{\Sch/k}(V,W)\\
		&\simeq\Hom_{\Alg_k}(S^\ast(W^\vee),S^\ast(V^\vee))\\
		&\simeq\Hom_{\Alg_k}(W^\vee,S^\ast(V^\vee))\\
		&\simeq W\otimes S^\ast(V^\vee)
	\end{align*}
	where we used above properties of affine schemes and standard facts of the linear algebra of finite dimensional vector spaces as well as the fact that 
	a map from $S^\ast(V)$ is determined uniquely by its images on $V$.
\end{rmk}
For reasons that will become apparent shortly, it is easier to use the above remarks to define a 
polynomial map in the following way:
\begin{defn}
	If $V,W\in\Vectk$ are finite dimensional, a \textbf{polynomial map $f:V\to W$} can be alternatively defined as an element 
	\[f\in W\otimes S^\ast(V^\vee)\cong\Hom_{\Sch/k}(V,W)\]
	through the identifications above.
\end{defn}

The upshot to this seemingly more \textit{ad hoc} definition is that, while it introduces the restriction of finite dimensionality (which will suffice for our 
definitions anyways), it enables us to make more simple the following idea:
\begin{defn}\label{def:homog-poly-map}
	Let $V$ and $W$ be vector spaces. Then a map $f\in \Hom_\text{Pol}(V,W)$ is called \textbf{homogeneous degree $d$} if 
	it corresponds (under the isomorphisms above) to an element 
	\[f\in W\otimes S^d(V^\vee).\]
\end{defn}
This is clearly a tangible and sensible way to define a degree $d$ map and it is less obvious how to define a property 
on the map of corresponding varieties that achieves the same goal. We will see in the next subsection other ways to define this 
notion that may appeal more to representation theorists.
\begin{ex}
	Here are some examples of polynomial maps:
	\begin{itemize}
		\item The identity (scheme) map $\id:V\to V$ is a (homogeneous degree 1) polynomial map. This corresponds to the element 
		\[\sum_{i=1}^n v_i\otimes v_i^\vee\in V\otimes S^\ast(V^\vee)\]
		where $v_1,\dots,v_n$ is a basis for $V$.
		\item If $V=\langle v_1,\dots,v_n\rangle$ and $W=\langle w_1,\dots,w_m\rangle$, the element
		\[\sum_1^m w_i\otimes (v_i^\vee\otimes v_i^\vee)\]
		gives rise to a map of algebras that sends basis element
		\[\sum_{\sigma\in\frakS_k}w_{i_{\sigma(1)}}^\vee\otimes \cdots\otimes w_{i_{\sigma(k)}}^\vee\mapsto \sum_{\sigma\in\frakS_k}v_{i_{\sigma(1)}}^\vee\otimes v_{i_{\sigma(1)}}^\vee\otimes \cdots\otimes v_{i_{\sigma(k)}}^\vee\otimes v_{i_{\sigma(k)}}^\vee\]
		which corresponds to a homogeneous degree 2 polynomial (scheme) map $V\to W$.
	\end{itemize}
\end{ex}

\subsection{The categories \texorpdfstring{$\calP_k$}{Pk} and \texorpdfstring{$\Rep \Gamma^d_k$}{Rep Gdk}}
Before we define these categories we should describe the objects in question!
\begin{defn}
	A \textbf{strict polynomial functor} is a functor $T:\Vect_k\to \Vect_k$ such that for any $V,W\in\Vect_k$,
	the map on $\Hom$s
	\[T_{V,W}:\Hom_k(V,W)\to \Hom_k(T(V),T(W))\]
	is a polynomial map. That is,
	\[T_{V,W}\in\Hom_\text{Pol}\big(\Hom_k(V,W), \Hom_k(T(V),T(W))\big)\]
\end{defn}

Earlier I promised that we would have a more representation-theoretic interpretation of the homogeneous degree 
of a strict polynomial functor. I am nothing if I am not true to my word:
\begin{lem}[Lem. 2.2 in \cite{friedlander-suslin}]
	Let $T$ be a strict polynomial functor and let $n\ge 0$ be an integer. Then the following conditions are equivalent:
	\begin{enumerate}
		\item For any $V\in\Vectk$, any field extension $k'/k$ and any $0\ne\lambda\in k'$, the $k'$-linear 
		map $T_{k'}(\lambda\cdot 1_{V_{k'}})\in\End_{k'}(T(V)_{k'})$ coincides with $\lambda^n1_{T(V)_{k'}}$.
		\item For any $V\in\Vectk$, $n$ is the only weight of the representation of the algebraic group $\Gm$ in $T(V)$
		obtained by applying $T$ to the evident representation of $\Gm$ in $V$.
		\item For any $V,W\in\Vectk$, the polynomial map 
		\[T_{V,W}:\Hom_k(V,W)\to \Hom_k(T(V),T(W))\] 
		is homogeneous of degree $n$ (in the sense of \ref{def:homog-poly-map}).
	\end{enumerate}
\end{lem}
\begin{prf}
	\color{red} Spell this out. 
\end{prf}

\begin{defn}
	The category $\calP_d$ is the full subcategory 
	\[\calP_d\subset\Func(\Vectk,\Vectk)\]
	whose objects are the \textbf{strict polynomial functors of degree $d$.}
\end{defn}

\begin{thm}
	The map
	\[\Psi:\calP_d\to \lmod {S(n,d)}\]
	given by evaluation at $k^n$:
	\[T\mapsto T(k^n)\]
	is an equivalence of categories.
\end{thm}
\begin{prf}
	\color{red} refactor the proof from Friedlander and Suslin.
\end{prf}

\subsubsection{Yet another category}
Just when you thought you had enough categories to work in, Krause developed a new category that more succinctly captures
the stucture of homogeneous degree $d$ polynomial maps: there the author changes the domain of these functors 
to encode the desired properties automatically.
\begin{defn}
	Let $k$ be any commutative ring. Then $P_k\subset \Vect_k$ is the full subcategory of finitely-generated projective $k$-modules.

	Define $\Gamma^d P_k$ to be the category of \textbf{divided powers}---the objects are the same as those of $P_k$, but such that 
	\[\Hom_{\Gamma^dP_k}(V,W)=\Gamma^d\Hom_{P_k}(V,W)\]
	where $\Gamma^d X=(X^{\otimes d})^{\frakS_d}$ denotes the \textbf{$d^{\text{th}}$} divided powers of the $k$-module $X$.

	Finally, as a matter of notation, let 
	\[\Rep\Gamma^d_k=\Rep\Gamma^dP_k=\Func(\Gamma^dP_k,\lmod k)\]
	which we (suggestively) call the \textbf{category of homogeneous degree $d$ strict polynomial functors.}
\end{defn}
\begin{rmk}
	Of course, when $k$ is a field, we get that $P_k=\Vectk$ and an element
	\[T\in\Rep\Gamma^d_k=\Func(\Gamma^d\Vectk,\Vectk),\]
	is a functor that, on objects, is a map $\Vectk\to \Vectk$ and on morphisms is of the form 
	\[T_{VW}:\Hom_{\Gamma^d\Vectk}(V,W)=\Gamma^d\Hom_k(V,W)\to \Hom_k(T(V),T(W))\]
	which, while not exactly our definition of a polynomial map, suggests some level of similarity.
\end{rmk}

{\color{red} Finish up proving that this category is also equivalent. Maybe try to see if I can cook up an equivlence directly between $\calP_d$ and $\Rep\Gamma^d_k?$}

\subsection{Monoidicity of \texorpdfstring{$\calF$}{F}}
{\color{red} Define Henning's monoidal structure on $\Rep\Gamma^d_k$ and go through Aquilino and Reischuk's proof 
the SW functor is monoidal under this definition.}

\subsection{A dictionary}
{\color{red} Spell out how one can translate between the three different categories: irreducibles and tensor structure.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Tensor products in the derived category \texorpdfstring{$\Db(S(n,r))$}{DbS(n,r)}}
{\color{red} Do some definitions here for derived category stuff and talk about how the induced tensor product from before compares with the one 
naturally on $\Db(S(n,r))$}
\subsection{Derived categories}

\subsection{Compatibility of monoidal structures}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{The (Balmer) spectrum of a tensor triangulated category}
In Paul Balmer's 2005 paper \cite{balmer-spc}, he developed a general framework for understanding the structure of certain 
kinds of categories that arose from the original constructions in algebraic geometry. Serving as a source of inspiration for Balmer, in \cite{friedlander-pevtsova-pi} Friedlander and Pevtsova proved
that the projective geometry of the cohomology ring of a finite group scheme can be recovered by looking at ``ideals'' in the category $\stmod G$ 
of stable $G$ modules.

Using this as a springboard, Balmer ported the definitions of ideals and prime ideals to tensor-triangulated categories (see below)
and proved a broader result that gives some tools for better analyzing familes of representaitons of finite groups (among other things).
\subsection{Some motivation and a definition}
Let $\calC$ be a symmetric monoidal (i.e. tensor) category with tensor product $\otimes$ and unit object $\1$. After giving some 
thought to the matter, one realizes that a ring is given by putting a ``compatible'' monoidal structure on top of an abelian group,
and to that end, one may consider the case when $\calC$ is also additive. 

This perspective gives us an interesting analogy between (unital, commutative) rings in algebra and category theory. Since every 
triangulated category is also additive, we can further specify that $\calC$ be triangulated:
\begin{defn}
	A \textbf{tensor-triangulated} category $\calC$ is both a moniodal category and a triangulated category such that 
	the monoidal structure preserves the triangluated structure. 

	As a reminder, such a category is equipped with a tensor product $-\otimes -:\calC\times\calC\to \calC$ and unit object $\1$, along with
	a collecton distinguished triangles $\calT$ comprised of objects in $\calC$ and shift functor (an auto-equivalence) $(-)[1]:\calC\to \calC$ such that:
	$-\otimes-$ is a triangulated (or exact) functor in each entry (it takes $\calT$ to itself).
\end{defn}

\subsubsection{Aside: Why triangulation?}
{\color{red} Look into and figure out why we need stability here to make sense of things.}

\subsection{Construction of the spectrum}
Once the appropriate context is identified (which is the real ingenuity of Balmer's paper), the construction 
very closely mirrors the construction seen in elementary algebraic geometry:
\begin{defn}
	Let $\calC$ be a tensor-triangulated category (TTC). Then a \textbf{(thick tensor) ideal} $I\subseteq \calC$ is a full triangulated subcategory 
	with the following conditons:
	\begin{itemize}
		\item \textit{(2-of-3 rule/Triangulation)} If $A,B,$ and $C\in\calC$ are objects that fit into a distinguished triangle
		\[A\to B\to C\to A[1]\]
		in $\calC$, and if any two of the three are objects in $I$, then so is the third.
		\item \textit{(Thickness)} If $A\in I$ is an object that splits as $A\cong B\oplus C$ in $\calC$, then both $A$ and $B$ belong to $I$.
		\item \textit{(Tensor Ideal)} If $A\in I$ and $B\in \calC$ then $A\otimes B=B\otimes A\in I$.
	\end{itemize}
\end{defn}

\begin{rmk}
	The first condition just ensures that our ideals respect the triangulated structure (and thus stability) in the parent category $\calC$. 
	The final condition is the most direct analog of an ideal and is central in the analogy between this theory and classical AG.
\end{rmk}
From here the rest of the picture is relatively straightforward:
\begin{defn}
	Let $\calC$ be a TTC as before. Then an ideal $I\subseteq\calC$ is called a \textbf{prime ideal}
	if, whenever $A\otimes B\in I$ for some $A,B\in \calC$, either $A$ or $B$ is in $I$.

	We call the collection of all primes the \textbf{spectrum} of $\calC$ and write 
	$\operatorname{Spc}(\calC)$.
\end{defn}

Here the construction varies slightly from the traditional construction of $\Spec$: we define 
\[Z(S)\eqdef\{\calP\in\Spc(\calC)|S\cap\calP=\varnothing\}\]
and define sets (for any $S\subseteq\calC$ and $A\in \calC$):
\[U(S)\eqdef \Spc(\calC)\setminus Z(S)=\{\calP\in\Spc(\calC)|S\cap \calP\ne\varnothing\}\]
and
\[\supp(A)\eqdef Z(\{A\})=\{\calP\in\Spc\calC|A\notin \calP\}\]

A routine check of the axioms shows us
\begin{lem}[2.6 of \cite{balmer-spc}]
	The sets $U(S)$ for all $S\subseteq\calC$ form a basis for a topology on $\Spc\calC$.
\end{lem}
which we call the \textbf{Zariski topology}, giving $\Spc\calC$ the structure of a topological space.

\subsection{As a locally-ringed space}
The above discussion mentions how we can construct a topological space from the set of prime thick tensor ideals 
in a TTC, but there is even more we can get: the structure of a locally-ringed space. 

To get this, we need to define the structure sheaf:
\begin{defn}
	Let $\calC$ be a tensor-triangulated category and let $\Spc\calC$ be the construction discussed above. Then the structure sheaf on $\Spc\calC$ is given by the 
	sheafification $\O_\calC$ of the presheaf 
	\[\tilde\O_\calC:\operatorname{Open}(\Spc\calC)\op\to \Ring\]
	given by 
	\[\tilde\O_\calC(U)\eqdef \End_{\calC/\calC_Z}(\1_U)\]
	where $U\subseteq\Spc\calC$ is an open set and $\calC_Z$ is the thick tensor ideal in $\calC$ supported 
	on $Z=\Spc\calC\setminus U$.
\end{defn}

\begin{rmk}
	That $\calC_Z$ is a thick tensor ideal requires some work, but it follows from work that Balmer does to 
	define a support data $(X,\sigma)$ on a tensor-triangulated category and showing that for any subset $Y\subset X$ of 
	its associated topological space, the following set 
	\[\{A\in\calC|\sigma(A)\subseteq Y\}\]
	is a thick tensor ideal of $\calC$ (c.f. lem.~3.4).
\end{rmk}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Questions and extensions}
\subsection*{The representation theory of \texorpdfstring{$S(n,r)$}{S(n,r)} in positive characteristic}

\subsection*{Computing the spectrum of \texorpdfstring{$\Db(S(n,r))$}{DbS(n,r)}}


\section*{Acknowledgements}
\label{sec:ack}
\addcontentsline{toc}{section}{\nameref{sec:ack}}
I extend my most heartfelt thanks to my advisor, Julia Pevtsova, who not only helped me immensely in setting a target 
for this project, but also introduced me to many of the classical ideas found in this paper (some times more than once). 
Her knowledge and understanding while I learned this subject has been absolutely invaluable to me.

My thanks also to my loving partner Allison, who stands beside me in good times and in bad and always patiently humors me when 
I need someone to listen to my inane ramblings.

Finally, thank you to my friends and colleagues in the University of Washington math department for many fruitful conversations 
and inspiration for ideas to investigate along the way. In particular I am indebted to (in no particular order) Thomas Carr, Sean Griffin, Sam Roven, and Cody Tipton
for all their help and support.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%  Bibliography %%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\medskip

\printbibliography
\addcontentsline{toc}{section}{References}

\end{document}