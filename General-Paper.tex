\documentclass[12pt]{article}

\usepackage{setspace}

\usepackage{graphicx, color, fancyhdr, tikz-cd, enumitem, framed, adjustbox, bbm, upgreek, xcolor, manfnt}
\usepackage[framed,thmmarks]{ntheorem}
\usepackage[framemethod=tikz]{mdframed}
\usepackage{hyperref}

\hypersetup{
	colorlinks = true,
	linkcolor = [rgb]{0,0,0.5},
	citecolor = [rgb]{0.6,0,0},
	urlcolor = [rgb]{0,0,0.5}
}
\usepackage[style=alphabetic, bibencoding=utf8]{biblatex}
%Set the bibliography file
\bibliography{sources}

\usepackage[T1]{fontenc}
\usepackage[urw-garamond]{mathdesign}
\usepackage{garamondx}
\let\mathcal\relax
\newcommand{\mathcal}[1]{\text{\usefont{OMS}{cmsy}{m}{n}#1}}

%Document-Specific includes
\usepackage{ytableau}
\usepackage{mathtools}
\usepackage{scalerel}

%Replacement for the old geometry package
\usepackage{fullpage}
\usepackage{amsmath}

%Input my definitions
\input{./mydefs.tex}

%Shade definitions
\theoremindent0cm
\theoremheaderfont{\normalfont\bfseries} 
\def\theoremframecommand{\colorbox[rgb]{0.9,1,.8}}
\newshadedtheorem{defn}[thm]{Definition}

%Set apart my theorems and lemmas and such
\surroundwithmdframed[outerlinewidth=0.4pt,
  innerlinewidth=0pt,
  middlelinewidth=1pt,
  middlelinecolor=white,
  topline=false,bottomline=false,rightline=false,leftmargin=2em]{thm}
\surroundwithmdframed[outerlinewidth=0.4pt,
  innerlinewidth=0pt,
  middlelinewidth=1pt,
  middlelinecolor=white,
  topline=false,bottomline=false,rightline=false,leftmargin=2em]{lem}
\surroundwithmdframed[outerlinewidth=0.4pt,
  innerlinewidth=0pt,
  middlelinewidth=1pt,
  middlelinecolor=white,
  topline=false,bottomline=false,rightline=false,leftmargin=2em]{cor}
  \surroundwithmdframed[outerlinewidth=0.4pt,
  innerlinewidth=0pt,
  middlelinewidth=1pt,
  middlelinecolor=white,
  topline=false,bottomline=false,rightline=false,leftmargin=2em]{prop}
  \surroundwithmdframed[outerlinewidth=0.4pt,
  innerlinewidth=0,
  middlelinewidth=1pt,
  middlelinecolor=white,
  topline=false,bottomline=false,rightline=false,leftmargin=2em]{rmk}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%% Customize Below %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%header stuff
\setlength{\headsep}{24pt}  % space between header and text
\pagestyle{fancy}     % set pagestyle for document
\lhead{General Exam Paper} % put text in header (left side)
\rhead{Nico Courts} % put text in header (right side)
\cfoot{\itshape p. \thepage}
\setlength{\headheight}{15pt}
%\allowdisplaybreaks

% Document-Specific Macros
\newcommand*{\ttc}{{\large $\triangle$}\kern-0.86em\raisebox{0.3ex}{$\scaleobj{0.78}\otimes$}\hspace{1ex}}
\DeclareMathOperator{\Spc}{Spc}

\begin{document}
%make the title page
\title{General Exam Paper \vspace{-1ex}}
\author{Nico Courts\footnote{University of Washington, Seattle. Email: ncourts@uw.edu}}
\date{Exam Presentation: March 10th, 2020}
\maketitle

\begin{abstract}
	We begin by going through a considerable amount of domain knowledge concerning representations of $\GL_n$,
	representations of $\frakS_n$, and strict polynomial functors all in service of understanding the Schur-Weyl 
	functor that relates several of these categories. From there, we investigate recent work on the part of Krause 
	and his students Aquilino and Reischuk on this functor and the fact that it is monoidal under reasonably natural monoidal structures on 
	the categories in question. Finally we ask some questions about whether the monoidal structure on strict polynomial functors 
	extends meaningfully to pathologies that arise in positive characteristic.

	{\footnotesize An up-to-date version of this paper can be downloaded at the following link: \url{https://github.com/NicoCourts/General-Exam-Paper/raw/master/General-Paper.pdf}}
\end{abstract}

\newpage
\renewcommand{\baselinestretch}{0.75}\normalsize
\setcounter{tocdepth}{3}
\tableofcontents
\renewcommand{\baselinestretch}{1.0}\normalsize

\newpage
\section{Introduction}
\subsection{Issai Schur and polynomial representations}
The story of this project (more-or-less) begins with Schur's doctoral thesis \cite{schur-thesis} in which he defined
polynomial representations of $\GL_n$---a theory which he developed more completely in his later paper \textit{\"Uber die 
rationalen Darstellungen der allgemeinen linearen Gruppe}\footnote{English: \textit{On the rational representations of the general linear group}}
\cite{schur-rational}. In these papers, Schur develops the idea of a \textbf{polynomial representation of $\GL_n$},
meaning a (finite dimensional) representation where the coefficient functions of the representing map 
\[\rho:\GL_n\to \GL(V)\]
is polynomial in each coordinate. For example, the map sending 
\[A=\begin{pmatrix}
	a&b\\
	c&d
\end{pmatrix}\mapsto \begin{pmatrix}
	a^2d-abc & acd-c^2b & 0\\
	abd-b^2c & ad^2-bcd & 0\\
	0 & 0 & ad-bc
\end{pmatrix}=\rho(A)\]
is a three-dimensional polynomial representation of $\GL_2$.

The block-diagonal form above demonstrates a direct sum decomposition of our representation into two parts: one two-dimensional homogeneous degree 3
and one one-dimensional homogeneous degree 2 (in the entries of $A$). A result in \cite{schur-thesis} tells us that, in fact, this can always be done: 
if $V$ is a polynomial representation of $\GL_n$,
then $V$ decomposes as a direct sum of representations 
\[V=\bigoplus_\delta V_\delta\]
where each $V_\delta$ is a polynomial representation where the coefficient functions are \textit{homogeneous degree $\delta$}. 
This allows us to focus our attention to the structure of these $V_\delta$ as the fundamental building blocks of the theory.

The key insight made in this theory comes from the observation that the vector space (recall $V\cong k^n$)
\[E=V^{\otimes r}\]
is made into a $(\GL_n(k),\frakS_r)$-bimodule in a very natural way, and that this bimodule gives us a way to relate 
$\rmod {\frakS_r}$ with (a subcategory of) $\lmod {\GL_n(k)}$ via the so-called \textbf{Schur-Weyl functor.}

\subsection{The Schur-Weyl functor}
Clearly a connection between representations of two groups that are so ubiquitous in group theory and math in general 
is a stunning observation, and much effort has been expended since the late 20th century to study this functor and its 
properties---especially in how it relates the representation theory of these two groups. 

For instance, Friedlander and Suslin \cite{friedlander-suslin}
originally discussed the idea of \textbf{strict polynomial functors} and showed that the category of repesentations 
of the Schur algebra $S(n,d)$ was equivalent to the category $\calP_d$ of homogeneous degree $d$ strict polynomial functors.

In later work, Krause \cite{krause-strict-poly-func} used an alternative construction of $\calP_d$ as the category of
of reprsentations of the $d$-divided powers of the category of finitely generated projective $k$-modules. The upshot being that 
the latter object $\Gamma^d P_k$ has an obvious monoidal structure which $\calP_d$ inherits in a natural way. This new concrete 
monoidal structure opens up the field to discussing several notions of duality defined in different contexts 
and solidifying connections between them.

Krause's students Aquilino and Reischuk, in their paper \cite{aquilino-reischuk}, prove, among other facts, that 
under these natural monoidal structures the Schur-Weyl functor is in fact monoidal. This puts the theory of representations 
of these groups and algebras firmly in the realm of monoidal categories, opening up the area to new questions using 
tools from category theory.

\subsection{Notation and conventions}\label{subsec:notation}
Throughout this paper we will define $k$ to be a field (not necessarily of characteristic zero or algebraically closed unless otherwise noted).
%Let $\Alg_k$ be the category of $k$-algebras and $\Grp$ denote the category of groups with homorphisms.

We will use $\Gamma=\Gamma_k=\GL_n=\GL_n(k)$ to denote the general linear group, $\Aut_k(k^n)$. Let $\frakS_r$ denote the symmetric group on $r$ letters.

When speaking of the ($k$) vector space spanned by elements $v_1,\dots,v_n$, we will use the notation 
\[\langle v_1,\dots, v_n\rangle.\]

{\color{red} When the rest of the paper is finished, the intro will be rewritten to reflect the actual content.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage
\section{Representations of \texorpdfstring{$\Gamma$}{Gamma} and of \texorpdfstring{$\frakS_n$}{Sn}}
We begin by detailing the theory behind the (polynomial) representations of $\GL_n$ as well as the representations of $\frakS_n$ to 
familiarize ourselves with the classical representation theory associated to these groups.

\subsection{Representations of \texorpdfstring{$\frakS_n$}{Sn}}
The representation theory for $\frakS_n$ over the complex numbers is a subject that has been widely studied by representation theorists 
and combinatorialists alike for over a century. Before we dive into specifics, we write down the idea originally worked out by Frobenius \cite{frobenius-charaktere}
in his work in 1900 on the characters of $\frakS_n$:
\begin{thm}\label{thm:frob-conj}
	The conjugacy classes (and thus isomorphism classes of irreducible representations over $\bbC$) of $\frakS_n$
	are in bijection with partitions of $n$.
\end{thm}

\begin{rmk}
	In what follows we attempt to give a tangible, minimalistic overview of the nicest case of representations of $\frakS_n$.
	Some of the arguments below appeal more to intuition and examples than rigor, but we feel this better prepares the reader 
	for computations in $\frakS_n$ without being weighed down by unnecessary details. This can all be made rigorous, of course, 
	at the expense of some clarity and conciseness. 
\end{rmk}
Let's get some sense first about how we can relate these two ideas by recalling some easy lemmas from 
group theory. Recall that each element of $\frakS_n$ can be written 
as a product of disjoint cycles and that this representation is unique up to reordering the cycles. We can make this 
representation unique by writing each cycle as one starting at its least element and then ordering the cycles by these least elements. 
For instance, the permutation (in two-line notation)
\[\sigma=\begin{pmatrix}1&2&3&4&5&6&7&8\\ 2&1&7&5&3&8&4&6\end{pmatrix}\in\frakS_8\]
is represented uniquely in this way as the product of cycles:
\[\sigma=(1\,2)(3\,7\,4\,5)(6\,8).\]

The next observation to recover: if $\tau,\eta\in\frakS_n$ and $\tau=(\tau_1\,\tau_2\,\cdots\,\tau_k)$ is a cycle, 
\[\eta^{-1}\tau\eta=(\eta(\tau_1)\,\eta(\tau_2)\,\cdots\,\eta(\tau_k)).\]
We can see this demonstrated in the computation
\begin{align*}
	(1\,3\,5)\sigma(1\,3\,5)^{-1}&=(1\,3\,5)(1\,2)(1\,5\,3)(1\,3\,5)(3\,7\,4\,5)(1\,5\,3)(1\,3\,5)(6\,8)(1\,5\,3)\\
	&=(3\,2)(5\,7\,4\,1)(6\,8)\\
	&=(1\,5\,7\,4)(2\,3)(6\,8)
\end{align*}
The important observation here is that the ``shape'' (the lengths of the cycles when written as a product of disjoint cycles) is preserved under conjugation.
In fact,
\begin{lem}\label{lem:conj-classes}
	The conjugacy classes of $\frakS_n$ are in one-to-one correspondence with the partitions of $n$.
\end{lem}
\begin{prf}
	Let $\scrP_n$ denote the partitions of $n$ and let $C_n$ denote the conjugacy classes in $\frakS_n$.
	We construct the set map 
	\[\varphi:C_n\to \scrP_n\]
	by sending a conjugacy class to the weakly-decreasing list of cycle lengths (including trivial cycles, if necessary). For instance in $\frakS_8$,
	\[(1\,5\,3)(2\,7)\qquad\text{cooresponds to}\qquad (3,2,1,1,1).\]

	The results cited and demonstrated above shows that this map is well defined---conjugation preserves the cycle length in 
	the disjoint cycle representation of an element. Furthermore if $p\in \scrP_n$ is a partition, the adjoint action of $\frakS_n$ on $\varphi^{-1}(p)$
	is transitive, since if two elements have the same cycle lengths when written as disjoint cycles, we can line 
	the cycles up according to length and act by the permutation that ``puts labels in the right place''. If we look at $\sigma$ and the 
	element we found by conjugation above, we have 
	\begin{align*}
		(1\,2)(3\,7\,4\,5)(6\,8)\\
		(3\,2)(5\,7\,4\,1)(6\,8)
	\end{align*}
	where we notice that $1\mapsto 3$, $3\mapsto 5$, and $5\mapsto 1$, meaning that the cycle that takes the top element to the 
	bottom is $(1\,3\,5)$---although of course we already knew that. Another example are the elements $(1\,4\,5)$ and $(3\,2\,1)$. Here we want $1\mapsto 3$, $4\mapsto 2$ and $5\mapsto 1$.
	Thus one element that takes the first to the second is $(5\,1\,3)(2\,4)$. This demonstrates that the action is not faithful since we could also act by $(5\,1\,3\,7)(2\,4)(6\,8)$ and get the same element. 
	the important fact here is that $\frakS_n$ acts transitively on the elements of $1,\dots,n$, so there is always such an element.

	The surjectivity of this map is clear since we can write from any partition of $n$ a product of disjoint cycles corresponding to 
	this partition (which then must map to it) and injectivity is clear since the disjoint cycle representation is unique (up to reordering cycles, which doesn't affect the image $\varphi(x)$).
	This proves the lemma.
\end{prf}

From here, the standard result that (again, over $\bbC$) the conjugacy classes of a group are in bijection with the irreducible representations finishes demonstrating how 
theorem \ref{thm:frob-conj} is true. But a simple set bijection belies the depth of the connection here. 

\subsubsection*{Construction of the irreducible representations}
It is possible, through the idea of a Young symmetrizer, to directly link a Young diagram to the corresponding 
irreducible representation. Throughout this subsection, we will be relying on facts developed in \cite{fulton-harris}, 
although there is also a more complete combinatorial picture painted in Fulton's book \textit{Young Tableaux} \cite{fulton-tableaux}. 

To begin our discussion, consider the trivial representation within the left regular representation $\bbC\frakS_n$: 
it is a one-dimensional subspace spanned by the element 
\[x_1=\sum_{\sigma\in\frakS_n}\sigma\]
where you can see that this element is fixed by left multiplication, demonstrating that it has the trivial $\frakS_n$ action.
The subspace spanned by the element 
\[x_{-1}=\sum_{\sigma\in\frakS_n}(-1)^{\operatorname{sign}(\sigma)}\sigma\]
is the sign representation, where an element with sign 1 acts by -1. This is because
\[\operatorname{sign}(\tau\sigma)=\operatorname{sign}(\tau)+\operatorname{sign}(\sigma)\pmod{2}.\]

It ends up that these two representations form the two ``endpoints'' of the representation theory of $\frakS_n$. The exact sense in which this is 
true is captured through Young diagrams! For the purposes of illustration, let us return to our example above of $\frakS_8$. Here the trivial and sign representations 
correspond (repsectively) to the tableaux
\[\ytableausetup{smalltableaux,centertableaux}\ydiagram{8}\qquad\text{and}\qquad\ydiagram{1,1,1,1,1,1,1,1}\]
which, in turn, correspond to partitions $(8)$ and $(1,1,1,1,1,1,1,1)$ of $8$. The way to make this connection is through the definition 
of a \textit{Young symmetrizer:}
\begin{defn}
	Fix an $n\ge 1$ and let $\lambda$ be a partition of $n$. Then define two elements of $\bbC\frakS_n$, $a_\lambda$ and $b_\lambda$ in the following way:
	\[a_\lambda=\sum_{\sigma\in R(T_\lambda)}\sigma\qquad\text{and}\qquad b_\lambda=\sum_{\sigma\in C(T_\lambda)}(-1)^{\operatorname{sign}(\sigma)}\sigma\]
	where $T_\lambda$ is the Young diagram corresponding to $\lambda$ and given some labeling (say the canonical one that labels boxes left-to-right and top-to-bottom)
	$R(T_\lambda)$ (resp. $C(T_\lambda)$) denote the subgroups of $\frakS_n$ stabilizing the rows (resp. columns) of $T_\lambda$ under the action of $\frakS_n$ on the labels.

	Then the \textbf{Young centralizer} of $\lambda$ is 
	\[c_\lambda=a_\lambda b_\lambda\in\bbC\frakS_n.\]
\end{defn}

The canonical fillings of the diagrams above are\footnote{Here you can see yet another connection to disjoint cycle representations. Notice, under the map 
defined in lem.~\ref{lem:conj-classes}, that the conjugacy class corresponding to the trivial representation is the one consisting of ``long'' (length $n$) cycles. Using the 
unique ordering on products of disjoint cycles described after the statement of thm.~\ref{thm:frob-conj}, we can identify fillings with long cycles and we see 
that the cycle $(1\,2\,3\,4\,5\,6\,7\,8)$ is the only one in ``standard form'' in that it gives us a standard Young tableau. The complexity of the Young diagram (meaning how many 
different standard fillings it admits) gives us some information about the dimensionality of the corresponding irreducible representation, as we will see later.}
\[\ytableaushort{12345678}\qquad\text{and}\qquad\ytableaushort{1,2,3,4,5,6,7,8}\]
and so since the column stabilizer of the first diagram is trivial and the row stablizer is everything,
\[c_{(8)}=\left(\sum_{\sigma\in R(T_{(8)})}\sigma\right)\left(\sum_{\sigma\in C(T_{(8)})}(-1)^{\operatorname{sign}(\sigma)}\sigma\right)=\sum_{\sigma\in\frakS_n}\sigma=x_1\]
and since the roles of the column and row stabilizing elements are reversed for the sign representation, we get 
\[c_{(1,1,1,1,1,1,1,1)}=\left(\sum_{\sigma\in R(T_{(1,1,1,1,1,1,1,1)})}\sigma\right)\left(\sum_{\sigma\in C(T_{(1,1,1,1,1,1,1,1)})}(-1)^{\operatorname{sign}(\sigma)}\sigma\right)=\sum_{\sigma\in\frakS_n}(-1)^{\operatorname{sign}(\sigma)}\sigma=x_{-1}.\]

That the Young symmetrizers correspond with the elements spanning the corresponding representations of is no coincidence! 
\begin{defn}
	The module $V_\lambda$ is a $\bbC\frakS_n$-module generated by the Young symmetrizer $c_\lambda$.
\end{defn}
Notice that the dimension of each $V_\lambda$ is determined by number of linearly-independent elements that lie in the orbit of $c_\lambda$. We compute another example that 
gives a general pattern:
\begin{ex}
	Let $\lambda=(2,1,1)$ be the partition of $5$, so 
	\[T_\lambda=\ydiagram{2,1,1}.\]
	Given the canonical filling of $T_\lambda$,
	\[\ytableaushort{12,3,4},\]
	we have 
	\[a_\lambda=e+(1\,2)\qquad\text{and}\qquad b_\lambda=e-(1\,3)-(1\,4)-(3\,4)+(1\,3\,4)+(1\,4\,3)\]
	and so we can compute that the Young symmetrizer for this partition is 
	\[c_\lambda=e-(1\,3)-(1\,4)-(3\,4)+(1\,2)+(1\,3\,4)+(1\,4\,3)-(2\,1\,4)-(1\,2)(3\,4)+(1\,3\,4\,2)+(1\,4\,3\,2)\]
	and one can show (c.f. \cite[48]{fulton-harris}) that this is the representation $V\wedge V$ where $V$ is the standard representation 
	(the complement of copy of the trivial representation spanned by the vector $(1,1,1,1)\in\bbC^4$ under the usual embedding of 
	$\frakS_4$ in $\GL_4$ as permutation matrices).
\end{ex}

This completes the description of the representations of $\frakS_n$ over $\bbC$, but in fact everything we have done here holds over the splitting field 
of $\frakS_n$, that is, the minimal field such that representations don't split further under field extension. We haven't proved here that
\begin{enumerate}
	\item the $V_\lambda$ are irreducible; or 
	\item the $V_\lambda$ are pairwise nonisomorphic,
\end{enumerate}
but one can look up any of the standard texts (including the ones cited in this section) for more rigorous and thorough treatments of these facts.

\subsection{Polynomial representations of \texorpdfstring{$\Gamma$}{Gamma}}
Let $\Gamma$ be the affine group scheme defined in section~\ref{subsec:notation}. Then 
\begin{defn}
	A (finite dimensional) \textbf{representation} of $\Gamma$ is a (finite dimensional) vector space $V$ along with a map
	\[\rho:\Gamma\to \GL(V)\eqdef\Aut_k(V)\]
	where $\rho$ is a group homomorphism.
\end{defn}
\begin{rmk}
	Often in representation theory one combines the map $\rho$ and vector space $V$ into a single object:
	a $k\Gamma$-module. This simultaneously encodes the vector space structure (via $k$-linearity) and the action by 
	$\Gamma$.
\end{rmk}
Representations of $\Gamma$ can be, in general, ``analytic.'' One can check that the map 
\[\rho:k^\times=\GL_1(k)\to \GL(k^2)\qquad\text{via}\qquad x\mapsto\begin{pmatrix}
	1 & \ln |x|\\ 0 & 1
\end{pmatrix}\]
gives a group homomorphism (and thus representation) between these two groups, but the logarithm makes this representation decidedly \textit{not algebraic.}
To narrow our focus somewhat and ensure we stay within the realm of algebra, we make the following definition:
\begin{defn}\label{def:poly-rep}
	A \textbf{polynomial representation} of $\Gamma$ is a representation $\rho$ such that the structure maps of $\rho$ 
	are polynomials in the functions $c_{ij}:\Gamma\to k$ that extract the $(i,j)^{th}$ entry.
\end{defn}
\begin{rmk}
	Recall (or learn for the first time!) that the \textit{structure maps} of a representation $(\rho,V)$ are a collection 
	of maps $r_{ij}$ for $1\le i,j,\le n$ from $\Gamma$ to $k$ such that for all $g\in \Gamma$:
	\[g\cdot v_i=\sum_{j=1}^n r_{ij}(g)v_j\]
	where we have picked a basis $\{v_1,\dots,v_n\}$ for $V$. Of course changing basis may change our 
	$r_{ij}$, but an invariant of the representation is the \textbf{span} $\langle r_{ij}\rangle$.
\end{rmk}
\begin{rmk}
	If all $r_{ij}$ are homogeneous polynomials of the same degree, we say that $\rho$ is a \textbf{homogeneous polynomial representation} of $\Gamma$.
\end{rmk}
\begin{defn}\label{def:Mnr}
	Let $M_k(n)=M(n)$ be the collection of all polynomial representations of $\GL_n$ and let $M_k(n,r)=M(n,r)$ 
	be the collection of all degree $r$ polynomial representations of $\GL_n$.

	Generally speaking, we will identify both of these with an appropriate subcategory of $\lmod{k\Gamma}$.
\end{defn}
It is the \textit{polynomial} representations that we will concern ourselves with in the following sections. 

\subsubsection{Reducing scope}
Using some of our familiar friends from representation theory (as well as some clever twists), 
we can simplify this picture considerably by proving the following structural result:
\begin{thm}[{\cite[pp.7-10]{schur-thesis}}]\label{thm:decomp}
	Every polynomial representation $V$ over an infinite field $k$ decomposes as a direct sum 
	\[V\cong\bigoplus_{\delta\in\bbN}V_\delta\]
	where $V_\delta$ is a \textit{homogeneous} polynomial representation of degree $\delta.$
\end{thm}
Clearly, then, it suffices to understand the \textit{homogeneous degree $r$} polynomial representations of $\Gamma$ if we are looking
to understand the larger structure.

We begin with a useful lemma extracted from a proof in \cite{schur-thesis} echoing the general theory of 
orthogonal decomposition of Artinian algebras.
\begin{lem}\label{lem:orth-decomp}
	Let $C_0,\dots,C_m\in M_n(k)$ be mutually orthogonal idempotent matrices that sum to the identity. That is, 
	\[I_n=\sum_i C_i\quad\text{and}\quad C_iC_j=\delta_{ij}C_i\]
	for all $0\le i,j\le m$. Then there exists an invertible matrix $P$ such that for some positive integers $d_0,\dots,d_m$ with $\sum_k d_k=n$ and for all $i$,
	\[P^{-1}C_iP=\begin{pmatrix}
		\mathbf{0}_{N_i} & &\\
		& I_{d_i} & \\
		& & \mathbf{0}_{M_i}
	\end{pmatrix}\]
	Where $N_i=\sum_{0\le j<i}d_j$ and $M_i=n-d_i-N_i$
\end{lem}
\begin{prf}[of lem~\ref{lem:orth-decomp}]
	We set $S_k=\{C_0,C_1,\dots,C_k\}$ and we proceed by induction on $k$. When $k=0$, $S_k=\{C_0\}$. Now since 
	$C_0^2=C_0$, we get that 1 and 0 are the only eigenvalues of $C_0$, so there is an $r\times r$ matrix $P_0$ 
	and a positive integer $d_0$ such that
	\[P_0^{-1}C_0P_0=\begin{pmatrix}
		I_{d_0} & \\
			& \mathbf{0}_{n-d_0}
	\end{pmatrix}.\]
	which establishes the base case.

	Now assume that we have a matrix $P_{k-1}$ such that this property holds for all elements of $S_{k-1}$.
	Define, for each $0\le i\le k$, 
	\[C_i'\eqdef P^{-1}_{k-1}C_iP_{k-1}\]
	and since the $C_k$ is assumed to be orthogonal to all other $C_i$,
	\[C_k'=\begin{pmatrix}
		\mathbf{0}_{N_k} & \\
		& D_k
	\end{pmatrix}\]
	for some $D_k$.

	Now by properties of block diagonal matrices, we have 
	\[D_k^2=D_k\]
	so the eigenvalues of $D_k$ are again one and zero. Thus there is an invertible $Q\in \GL_{n-N_k}$ such that 
	\[Q^{-1}D_kQ=\begin{pmatrix}I_{d_k} &\\ & \mathbf{0}_{M_k}\end{pmatrix}\]
	and so by setting
	\[P_k\eqdef P_{k-1}\begin{pmatrix}I_{N_k} &\\ & Q\end{pmatrix}\]
	we can define
	\[C''_i\eqdef P_k^{-1}C_i P_k=\begin{pmatrix}I_{N_k} &\\ & Q\end{pmatrix}^{-1}C'\begin{pmatrix}I_{N_k} &\\ & Q\end{pmatrix}\]
	for $0\le i\le k$, we see immediately that $C_i'=C_i''$ for $0\le i<k$ and furthermore 
	\[C_k''=\begin{pmatrix}
		\mathbf{0}_{N_k} & \\
		& Q^{-1}D_kQ
	\end{pmatrix}=\begin{pmatrix}
		\mathbf{0}_{N_k} & &\\
		& I_{d_k} & \\
		& & \mathbf{0}_{M_k}
	\end{pmatrix}\]
	completing the inductive step. This this result holds for all $S_i$ and in particular for $S_m$, so the result is proven.
\end{prf}
As well as another result on a special class of commuting block diagonal matrices:
\begin{lem}\label{lem:block-diag}
	Let $k$ be an infinite field and let $A$ be a block diagonal matrix over $k$ of the form
	\[A=\operatorname{diag}(x^mI_{d_m},x^{m-1}I_{d_{m-1}},\dots,I_{d_0})\]
	where $d_i$ is (clearly) the dimension of the $(m-i)^{th}$ block and let $B$ be any matrix that commutes with $A$
	for every choice of $x\in k$. Then $B$ is block diagonal of the same shape as $A$. 
\end{lem}
\begin{prf}[of lem~\ref{lem:block-diag}]
	We proceed by comparing the entries in $AB$ and $BA$: notice that 
	\[(AB)_{ij}=\sum_k A_{ik}B_{kj}=A_{ii}B_{ij}=x^aB_{ij}\]
	and 
	\[(BA)_{ij}=\sum_k B_{ik}A_{kj}=B_{ij}A_{jj}=x^bB_{ij}.\]
	We will show that if the $(i,j)^{th}$ postion is not in one of the blocks of $A$, then it is zero.

	But if $(i,j)$ is not in one of the blocks of $A$, then the nonzero element in the $i^{th}$ row and the nonzero element in 
	the $j^{th}$ column ($x^a$ and $x^b$ in the above equations) are not the same! Since $x$ is arbitrary, this forces $B_{ij}=0$,
	so $B$ is block diagonal with blocks the same as $A$.
\end{prf}
\begin{rmk}
	Notice that in the above proof we used implicitly that there is an $x\in k$ such that for all $a,b$
	\[x^a=x^b\quad\Rightarrow\quad a=b\]
	which is true if (and only if!) $k$ is infinite. This is because any such $x$ must be a root of $x^n=x$ for some $n$, which 
	has finitely many roots over any field (but every element in $\bbF_p$ satisfies $x^p=x$).
\end{rmk}

And finally using these two lemmas allows us to prove our main result:
\begin{prf}[of thm~\ref{thm:decomp}]
	We recreate the argument in Schur's thesis, translated from German and reinterpreted in more modern parlance. 
	
	Let $(\rho,V)$ be a polynomial representation of $\Gamma$ with $\dim_k V=r$. Then let $x\in k^\times$ be arbitrary (thought of as an indeterminate)
	and consider the matrix $xI_n\in\Gamma$. The image of this matrix under $\rho$ is a matrix 
	\[\rho(A)=\begin{pmatrix}
		p_{11}(x) & \cdots & p_{1r}(x)\\
		\vdots & \ddots & \vdots\\
		p_{r1}(x) & \cdots & p_{rr}(x)
	\end{pmatrix}\]
	where each $p_{ij}$ is a polynomial in $x$. Let $m=\max_{i,j}\deg p_{ij}$, and this gives us a decomposition 
	\[\rho(A)=x^m C_0+x^{m-1}C_1+\cdots+ xC_{m-1}+C_m\]
	where each $C_i$ is an $r\times r$ matrix.

	Let $y$ be another indeterminate and $B=yI_n$. By virtue of being a representation of $\Gamma$, we get 
	\[\rho(A)\rho(B)=\rho(xI_n)\rho(yI_n)=\rho(xyI_n)=\rho(AB)\]
	and using this setup we prove the following result: 
	\[\text{For all $0\le i,j\le m$, with the $C_l$ as above,}\quad C_iC_j=\delta_{ij}C_i\]
	That this is true can be established by comparing coefficients in the equation
	\begin{align*}
		\rho(AB)&=\rho(A)\rho(B)\\
		C_0(xy)^m+\cdots+C_i(xy)^{m-i}+\cdots+C_m&=C_0^2x^my^m+\cdots+C_iC_jx^{m-i}y^{m-j}+\cdots+C_m^2
	\end{align*}
	Indeed, we immediately get that $C_i=C_i^2$ and furthermore the coefficients on $x^iy^j$ when $i\ne j$ give us
	\[0=C_{m-i}C_{m-j}.\]
	
	Thus we have shown that the $C_i$ form a set of orthogonal idempotent matrices and evaluating our original equation at $x=1$,
	we get (since $\rho$ is a homomorphism)
	\[I_r=1C_0+\cdots+1C_m=\sum C_i\]
	so the result from lemma~\ref{lem:orth-decomp} applies: we get a matrix $P$ such that 
	\[P^{-1}\rho(xI_n)P=\begin{pmatrix}
		x^mI_{d_0} & & & &\\
		& x^{m-1}I_{d_1} & & &\\
		& & \ddots & &\\
		& & & xI_{d_{m-1}} & \\
		& & & & I_{d_m}
	\end{pmatrix}\]
	Now let $\rho'(g)=P^{-1}\rho (g)P$ for all $g\in\Gamma$. This is a representation of $\Gamma$ since it it differs from $\rho$ by 
	an automorphism of $\GL(V)$. Since matrix multiplication is an algebraic operation, $\rho'$ is still a polynomial representation of $\Gamma$. 
	But notice that for all $g\in\Gamma$
	\[\rho'(g)\rho'(xI_n)=\rho'(xg)=\rho'(xI_n)\rho'(g)\]
	Then lemma \ref{lem:orth-decomp} gives us that $\rho'(g)$ decomposes in the same way for all $g\in \Gamma$, so 
	we know that $\rho'$ decomposes as a direct sum of representations 
	\[\rho'=\sum_{i=0}^m \rho'_i\]
	where for each $i$ and $\lambda\in k$,
	\[\rho'_i(\lambda g)=\rho_i'(\lambda I_{d_i})\rho_i'(g)=\lambda^i\rho'_i(g)\]
	so each $\rho_i'$ is a homogeneous degree $i$ polynomial representation of $\Gamma$.

	But of course the decomposition of a representation is independent of choice of basis,
	so we get a decomposition of $\rho$ into homogenous pieces, as desired.
\end{prf}

\subsubsection{Monomials and multi-indices}\label{subsubsec:indices}
All of the discussion up to this point has revolved around polynomials in $n^2$ variables, which quickly gets unwieldy unless one 
uses some better notation. To that end, 
\begin{defn}
	An $(n,r)$-\textbf{multi-index} $i$ is an $r$-tuple $(i_1,\dots,i_r)$ where each $i_j\in\underline n\eqdef\{1,\dots,n\}$.
	The collection of all $(n,r)$-multi-indices is denoted $I(n,r)$.
\end{defn}
\begin{rmk}
	One can also think of an element $i\in I(n,r)$ as a (set) map 
	\[i:\underline r\to\underline n.\]
\end{rmk}
The idea here is to associate to each monomial in a polynomial ring in many variables a tuple indicating its multidegree. That is we think of 
\[(i_1,\dots,i_r)\quad\leftrightsquigarrow\quad x_{i_1}\cdots x_{i_r}\]
as corresponding to the same object. Which is wonderful except for one small flaw: polynomials are commutative 
and multi-indices (as we have defined them) aren't! For example, in $I(3,4)$,
\[(2,2,1,3)\quad\leftrightsquigarrow\quad x_1x_2^2x_3\quad\leftrightsquigarrow\quad (3,2,1,2).\]

To handle this disparity, we define an equivalence relation on $I(n,r)$ where we say that $i\sim j$ if they are in the 
same orbit under the natural $\frakS_r$ action. That is, if there exists $\sigma\in\frakS_r$ such that
\[(i_1,\dots,i_r)=(j_{\sigma(1)},\dots,j_{\sigma(r)})\]

In the context of polynomial representations of $\Gamma$, we want to consider polynomials in the coordinate functions $c_{ij}$,
so as a matter of notation if $i,j\in I(n,r)$, let $c_{i,j}$ denote the monomial 
\[c_{i,j}=c_{i_1j_1}\cdots c_{i_rj_r}.\]
Again, we want to take into account that we can permute the order on the right hand side, but now we need that $i_k$ and $j_k$ 
remain linked to the same function. To deal with this, we define an equivalence relation $\sim$ on $I(n,r)\times I(n,r)$ such that 
\[(a,c)\sim (b,d)\]
if there exists a $\sigma\in\frakS_r$ such that 
\[(a_1,\dots,a_r)=(b_{\sigma(1)},\dots,b_{\sigma(r)})\quad\text{and}\quad(c_1,\dots,c_r)=(d_{\sigma(1)},\dots,d_{\sigma(r)}).\]
The upshot of this work is that it gives us a bijection between (total) degree $r$ monomials in the $c_{ij}$ and the set
\[I(n,r)\times I(n,r)/\sim\]

\subsubsection{\texorpdfstring{$A_k(n,r)$}{Ak(n,r)}}
Notice that if $V\in M(n,r)$, each of its structure maps are homogeneous degree $r$ polynomials. As the first object of study, consider 
\begin{defn}
	Let $A_k(n,r)=A(n.r)$ denote the collection of all homogeneous degree $r$ polynomials in the 
	coordinate functions $c_{ij}:\Gamma\to k$.
\end{defn}
It is not too hard to see that 
\begin{prop}
	$A_k(n,r)$ is spanned by the elements 
	\[\{c_{i,j}|(i,j)\in I(n,r)\times I(n,r)\}\]
\end{prop}
however it takes a short argument to see 
\begin{lem}
	The dimension of $A_k(n,r)$ over $k$ is $\binom{n^2+r-1}{n^2-1}=\binom{n^2+r-1}{r}$.
\end{lem}
\begin{prf}
	The following is a ``stars and bars'' argument that is pervasive in combinatorics. See for example \cite{stanley} if unfamiliar with these techniques.
	
	Fix an ordering of the $c_{ij}$ (say the dictionary order)
	and relabel them $\{\gamma_1,\dots,\gamma_{m}\}$ (here $m=n^2$) according to this order. Then the degree $r$ monomials are in bijection with $m$-tuples $(a_1,\dots,a_{m})\in\bbN^m$ such that $\sum_i a_i=r$ via the map which sends 
	\[(a_1,\dots,a_{m})\mapsto \gamma_1^{a_1}\cdots\gamma_{m}^{a_{m}}.\]

	But choosing such an element is the same as inserting $m-1$ bars into a line of $r$ stars (that is an ordered partition of $r$ into $m$ parts, 
	where parts are allowed to be zero). But this is equivalent to choosing $m-1$ bars in a field of $m+r-1$ symbols. This is just 
	\[\binom{m+r-1}{m-1}\]
	and a well-known identity for binomial coefficients gets us the final equality.
\end{prf}
\begin{ex}
	In case the reader is unfamiliar with this kind of reasoning, consider the case when $n=5$ and $r=4$. Then the composition $(1,0,0,2,1)$ corresponding to 
	$\gamma_1\gamma_4^2\gamma_5$ corresponds to the stars-and-bars diagram 
	\begin{center}
		$\ast|||\ast\ast|\ast$
	\end{center}
	where there are $m+r-1=8$ symbols, $r=4$ of which are stars.
\end{ex}

\subsubsection{A dip into affine group schemes and category theory}
$A(n,r)$ lies within $k^\Gamma=k(\Gamma)$, the $k$-algebra of functions $\Gamma\to k$, which has the structure of a Hopf algebra induced from the group 
structure on $\Gamma$. More precisely, the functor $\GL_n:\Alg_k\to \Grp$ that assigns to every $k$-algebra $A$ the group $\GL_n(A)$ is representable. In other words, 
\[\GL_n(-)\simeq \Hom_{\Alg_k}(R,-)\]
where $R\cong k[c_{ij}|1\le i,j\le n]_{\det}$.

The anti-equivalence of the categories of affine group schemes over $k$ and finite dimensional commutative $k$-Hopf algebras follows from Yoneda lemma 
(c.f. \cite[chp. 1]{waterhouse}), and along with this equivalence comes a way to translate the group structure on $\Gamma$ 
into a coalgebra structure on $R$: we have maps $\mu,\epsilon$, the multiplication and unit maps on $\Gamma$ satisfying the diagrams 
\begin{center}
	\begin{tikzcd}
		\Gamma\times\Gamma\times\Gamma\ar[r,"\mu\times\id"]\ar[d,"\id\times\mu"] & \Gamma\times\Gamma\ar[d,"\mu"]\\
		\Gamma\times\Gamma\ar[r,"\mu"] & \Gamma
	\end{tikzcd}
	\quad \begin{tikzcd}
		\ast\times G\ar[r,"\epsilon\times\id"] &G\times G\ar[d,"\mu"]& G\times \ast\ar[l,"\id\times\epsilon",swap]\\
		& G\ar[ur,leftrightarrow,"\sim"]\ar[swap,ul,leftrightarrow,"\sim"] &
	\end{tikzcd}
\end{center}
(where $\ast$ is the trivial group) giving us associativity and identity. Yoneda gives us that the maps between functors (group schemes!)
\[\mu:\Gamma\times\Gamma\to \Gamma\quad\text{and}\quad \epsilon:\ast\to\Gamma\]
give rise to maps in $\Alg_k$:
\[\Delta\eqdef\mu^\ast:R\to R\otimes_k R\quad\text{and}\quad \varepsilon\eqdef\epsilon^\ast: R\to k\]
satisfying diagrams 
\begin{center}
	\begin{tikzcd}
		R\otimes R\otimes R & R\otimes R\ar[l,"\Delta\otimes\id",swap]\\
		R\otimes R\ar[u,"\id\otimes \Delta"] & R\ar[u,"\Delta"]\ar[l,"\Delta"]
	\end{tikzcd}
	\quad\begin{tikzcd}
		k\otimes R\ar[dr,"\sim",leftrightarrow,swap] & R\otimes R\ar[l,"\varepsilon\otimes \id",swap]\ar[r,"\id\otimes\varepsilon"] & R\otimes k\ar[dl,"\sim",leftrightarrow]\\
		& R\ar[u,"\Delta"] &
	\end{tikzcd}
\end{center}
\begin{prop}
	The maps $\Delta$ and $\varepsilon$ give $R$ a coalgebra structure. In coordinates, if $1\le i,j\le n$,
	\[\Delta(c_{ij})=\sum_k c_{ik}\otimes c_{kj}\quad\text{and}\quad \varepsilon(c_{ij})=\delta_{ij}\]
\end{prop}
\begin{rmk}
	One can easily check that these maps make $R$ into a bialgebra by checking that $\Delta$ and $\varepsilon$ are algebra morphisms,
	but what is not immediately obvious is why \textit{these particular maps} are the ones we use on $R$. To 
	see this, one must dig into the Yoneda correspondence a bit to see what happens to the multiplication map.

	In service of this, let's translate matrix multiplication into a statement about representable functors. We want to define $m$ as a map 
	\[m:\Hom(R,-)\times\Hom(R,-)\to \Hom(R,-)\]
	and to see what $m$ should do in this context, we evaluate at a $k$-algebra 
	\[m_A:\Hom(R,A)\times\Hom(R,A)\to \Hom(R,A)\]
	where we interpret each map $R\to A$ as a matrix with entries in $A$ by saying a map $f$ corresponds to a matrix $A_f$ such that 
	\[(A_f)_{ij}=f(c_{ij}).\]

	Then if $(f,g)\in \Hom(R,A)\times\Hom(R,A)$, we want that the algebra structure is the usual matrix multiplication, so
	\[m_A(f,g)=A_fA_g\]
	and by computing the $(i,j)^{th}$ entry everywhere, we get 
	\[m_A(f,g)(c_{ij})=(A_fA_g)_{ij}=\sum_{k=1}^n(A_f)_{ik}(A_g)_{kj}=\sum_k f(c_{ik})g(c_{kj}).\]

	This gives us the values of our component maps everywhere, so this defines the natural transformation $m$. Then (the proof of)
	Yoneda tells us that we can compute the corresponding algebra morphism as 
	\[\mu(c_{ij})=m_{R\otimes R}(\iota_l\otimes\iota_r)(c_{ij})=\sum_k \iota_l(c_{ik})\iota_r(c_{kj})=\sum_k c_{ij}\otimes c_{kj}.\]
	Above we call $\iota_l$ (resp. $\iota_r$) to be the map $R\to R\otimes R$ which embeds $R$ into the left (resp. right) tensor factor. Notice 
	that $\iota_l\otimes\iota_r=\id_{R\otimes R}$.

	Using the same identification between maps and matrices over $A$, let $\ast:k\to A$ be the unique map sending $1_k\mapsto 1_A$. Then we want
	\[u_A(\ast)=f:R\to A\]
	corresponding to the identity $(n\times n)$ matrix over $A$. So 
	\[u_A(\ast)(c_{ij})=f(c_{ij})=(I_n)_{ij}=\delta_{ij}\cdot 1_A.\]
	Again applying Yoneda, we have 
	\[\varepsilon(c_{ij})=u_k(\id_k)(c_{ij})=\delta_{ij}1_k\]
	and we have our counit map.
\end{rmk}
In fact, as mentioned before, $R$ becomes a bialgebra (a Hopf algebra even, although we won't need the antipode here). This means that 
$\Delta$ and $\varepsilon$ are algebra morphisms for the natural algebra structure given by multiplication $m$ on $R$. In diagrams:
\begin{center}
	\begin{tikzcd}
		R^{\otimes 4}\ar[r,"\id\otimes\tau\otimes 1"] & R^{\otimes4}\ar[r,"m\otimes m"]  & R\otimes R\\
		R\otimes R\ar[u,"\Delta\otimes \Delta"]\ar[rr,"m"] & & R\ar[u,"\Delta"]
	\end{tikzcd}
	\quad\begin{tikzcd}
		R\otimes R\ar[r,"m"]\ar[d,"\varepsilon\otimes\varepsilon"] & R\ar[d,"\varepsilon"]\\
		k\otimes k\ar[r,"m"] & k
	\end{tikzcd}
\end{center}
where $\tau:R\otimes R\to R\otimes R$ is the twist map $a\otimes b\mapsto b\otimes a$. 
Chasing an element through the diagram on the left, we get
\[\tilde m\circ (\Delta\otimes \Delta)(c_{ij}\otimes c_{ab})=\sum_{1\le k,l\le n}c_{ik}c_{al}\otimes c_{kj}c_{lb}=\Delta(c_{ij}{c_{ab}})\]
or using our multi-index notation,
\[\Delta(c_{(i,a),(j,b)})=\sum_{(k,l)\in I(n,2)}c_{(i,a),(k,l)}\otimes c_{(k,l),(j,b)}.\]

Written more simply, the fact that $\Delta$ is an algebra morphism can be written 
\[\Delta(a\cdot b)=\Delta(a)\ast\Delta(b)\]
under suitable definitions of $\cdot$ and $\ast$. In a way that can be made precise, this means in particular that 
\[\Delta(a\cdot b\cdot c)=\Delta(a)\ast\Delta(b\cdot c)=\Delta(a)\ast\Delta(b)\ast\Delta(c)\]
and so on (since multiplication everywhere is associative) and therefore we can define this for arbitrary monomials and extend $k$-linearly: 
\begin{prop}
	If $i,j\in A(n,r)$, then 
	\[\Delta(c_{i,j})=\sum_{k\in I(n,r)}c_{i,k}\otimes c_{k,j}\quad\text{and}\quad \varepsilon(c_{i.j})=\delta_{i,j}\]
\end{prop}
One can easily see that degree is preserved by $\Delta$, meaning that 
\begin{prop}
	$\Delta$ and $\varepsilon$ descend to a coalgebra structure on $A(n,r)$. That is, $A(n,r)$ is a ($k$-)coalgebra.
\end{prop}

\subsubsection{The Schur algebra}
Finally we get to the actual object of study:
\begin{defn}\label{def:schur-alg}
	A \textbf{Schur algebra} is an element of the two-parameter family $\{S(n,r)\}=\{S_k(n,r)\}$ where $n$ and $r$ are any positive integers.
	As a set, $S(n,r)$ is the linear dual of $A(n,r)$:
	\[S(n,r)=A(n,r)^\ast=\Hom_k(A(n,r),k)\] 

	Let $\xi_{i,j}$ denote the element dual to $c_{i.j}\in A(n,r)$. In other words:
	\[\xi_{(a,b)}(c_{i,j})=\begin{cases}
		1, & (a,b)\sim(i,j)\\
		0, & \text{otherwise}
	\end{cases}\]
\end{defn}

\begin{lem}
	The coalgebra structure $(\Delta,\varepsilon)$ on $A(n,r)$ define an algebra structure on $S(n,r)$.
\end{lem}
\begin{prf}
	Since $k$ is an initial object in $\Alg_k$, there is a unique map $u:k\hookrightarrow S(n,r)$ sending $1$ to the unit function $\1$, which is given by 
	\[\1(c_{i,j})=c_{i,j}(I_n)=\delta_{i,j}\]
	Define multiplication $(\cdot)$ in $S(n,r)$ as follows: if $f,g\in S(n,r)$ then for any $x\in A(n,r)$ define 
	\[(f\cdot g)(x)=m_k\circ (f\otimes g)\circ \Delta(x)=\sum f(x_{(1)})g(x_{(2)})\]
	where $m_k:k\otimes k\to k$ denotes multiplication in $k$ and $\Delta(x)=\sum x_{(1)}\otimes x_{(2)}$ in Sweedler notation.

	Then we must just confirm that these maps satisfy the properties of a $k$-algebra. $(\cdot)$ is $k$-bilinear because (for instance)
	\begin{align*}
		((af+bg)\cdot h)(x)&=\sum (af+bg)(x_{(1)})\otimes h(x_{(2)})\\
		&=\sum a(f(x_{(1)})\otimes h(x_{(2)}))+b(g(x_{(1)})\otimes h(x_{(2)}))\\
		&= a\sum f(x_{(1)})\otimes h(x_{(2)})+ b\sum g(x_{(1)})\otimes h(x_{(2)})\\
		&=(a(f\cdot h)+b(g\cdot h))(x).
	\end{align*}
	
	By $k$-linearity, it suffices to show that the unit $\1$ acts as it should on the spanning set $\xi_{i,j}$ for a basis element $c_{a,b}$:
	\[(\1\cdot \xi_{i,j})(c_{a,b})=\sum_{k=1}^n \1(c_{a,k})\cdot\xi_{i,j}=\1(c_{a,a})\cdot\xi_{i,j}(c_{a,b})=\xi_{i,j}(c_{a,b})\]
	and a similar identity holds on the right.

	Then it remains to show that this multiplication is associative. Again by linearity it suffices to check that this works on the spanning set $\{c_{i,j}\}$:
	\begin{align*}
		((\alpha\cdot \beta)\cdot\gamma)(c_{i,j})&=\sum_{k\in I(n,r)}(\alpha\cdot\beta)(c_{i,k})\gamma(c_{k,j})\\
		&=\sum_k\left(\sum_{l\in I(n,r)}\alpha(c_{i,l})\beta(c_{l,k})\right)\gamma(c_{k,j})\\
		&=\sum_l\alpha(c_{i,l})\left(\sum_k \beta(c_{l,k})\gamma(c_{k,j})\right)\\
		&=\sum_l\alpha(c_{i,l})(\beta\cdot\gamma)(c_{l,j})\\
		&=(\alpha\cdot(\beta\cdot\gamma))(c_{i,j}).
	\end{align*}

	Thus since we have $k$-linear maps $\1$ and $m=(\cdot)$ satisfying the usual identity and associativity diagrams, $S(n,k)$ is a $k$-algebra 
	with $\1$ and $m$ as its unit and multiplication.
\end{prf}

Why have we done all this work to construct Schur algebras, one may ask? Well the idea is that there is a map
\[e:k\Gamma\to S(n,r)\]
where it sends 
\[\sum_i k_i g_i\mapsto \sum_i k_i e_{g_i}\]
where $e_g$ is the ``evaluation at $g$'' map--that is, for all $x\in A(n,r)$,
\[e_g(x)=x(g).\]
\begin{lem}\label{lem:e-surj}
	The map $e:k\Gamma\to S(n,r)$ is surjective.
\end{lem}
\begin{prf}
	Let $\xi$ be any element orthogonal to $W=\Im e$, if one exists. Say this element is $\sum_{i,j}a_{i,j}\xi_{i,j}$.
	But then the element $c=\sum a_{i,j}c_{i,j}$ is zero on every element in the image of $e$. In other words, for all $\kappa\in k\Gamma$,
	\[c(\kappa)=e_\kappa(c)=0.\]
	
	But the only function in $k^\Gamma$ that is zero on all of $\Gamma$ is the zero function. Thus $c=0$, whence its coefficients $a_{i,j}$ are zero. So $\xi$ is zero, so $W=S(n,r)$
\end{prf}

In this way, $e$ induces a map between categories
\[f:\lmod{S_k(n,r)}\to M_k(n,r)\]
where $f(V)=V$ as far as underlying sets are concerned, but we are given a new action: 
for any $\sum k_i g_i\in k\Gamma$ and $c\in V\in \lmod{S(n,r)}$,
\[\left(\sum k_i g_i\right)\cdot v=\left(\sum k_i e_{g_i}\right)\cdot v.\]
Notice that 
\begin{lem}
	$f$ as above defines a functor that sends any $\alpha:V\to W\in \lmod{S(n,r)}$
	to the map that is identical as a map of sets. 
\end{lem}
\begin{prf}
	Since we are working in a concrete category\footnote{There is a faithful functor to $\Set$; equivalently, any morphism is determined by where it sends the ``set of elements'' comprising the object.}, 
	and since the $V$ and $f(V)$ are identical as sets and since any morphism is sent to the same map on underlying sets, commutativity of 
	the functorality diagram 
	\begin{center}
		\begin{tikzcd}
			V\ar[r,"\alpha"]\ar[d,"f"] & W\ar[d,"f"]\\
			f(V)=V\ar[r,"f(\alpha)=\alpha"] & f(W)=W
		\end{tikzcd}
	\end{center}
	is trivial to check. It remains only to check that $f(\alpha):V\to W$ is a morphism in $M(n,r)$, so that this diagram makes sense.

	To check this, notice that for any $v\in V\in M(n,r)$ and $g\in k\Gamma$,
	\[f(\alpha)(g\cdot v)=\alpha(e_g\cdot v)=e_g\cdot \alpha(v)=g\cdot f(\alpha)(v)\]
	so $f$ is a functor.
\end{prf}
The upshot here is 
\begin{thm}
	The functor $f$ above is an equivalence of categories.
\end{thm}
\begin{prf}
	That $f$ is faithful is easy enough to see since $f$ is the identity functor on the level of underlying sets. Let $g:V\to W$ be a morphism in 
	$M(n,r)$ and consider the same (set) map in $\tilde g\in\lmod{S(n,r)}$. For any $\xi\in S(n,r)$, let $\kappa\in k\Gamma$ be an element such that $e_\kappa=\xi$
	(which exists due to lem~\ref{lem:e-surj}).
	Then 
	\[\tilde g(\xi\cdot v)=g(\kappa\cdot v)=\kappa\cdot g(v)=\xi\cdot \tilde g(v)\]
	But then $f(\tilde g)=g$, so $f$ is full.

	It remains to see that $f$ is essentially surjective. But again this is not too hard to see since for any $V\in M(n,r)$ the same object setwise with the action given by 
	\[\xi\cdot v=e_\kappa\cdot v\]
	(where again $\kappa$ was chosen using lem~\ref{lem:e-surj}) maps to $V\in M(n,r)$ and we are done.
\end{prf}
\begin{rmk}
	Actually, the above proof can be modified slightly to show that $f$ has a functorial inverse--that is, $f$ is an \textit{isomorphism of categories}.
	Since we are only interested in representations up to isomorphism, however, equivalence is just as good.
\end{rmk}
\begin{rmk}
	Using this equivalence, we identify $\lmod{S(n,r)}$ with $M(n,r)$ whenever it suits us.
\end{rmk}

One of a representation theorist's favorite kinds of results follows:
\begin{cor}\label{cor:semisimple}
	If $\ch k=0$, the algebra $S(n,r)$ is semisimple.
\end{cor}
\begin{prf}
	$k\Gamma$ is semisimple since $\ch k=0$, so every element in $\lmod{k\Gamma}$ splits into a direct sum of simple modules. But the irreducible objects in 
	$M(n,r)$ and those in $\lmod{S(n,r)}$ are the same and decompositons in one category pull back to the other, so every element in $\lmod{S(n,k)}$ is also completely reducible.
\end{prf}

\subsubsection{Weights and characters}
The discussion in section~\ref{subsubsec:indices} highlights an important idea: while we care about the \textit{quantities} in which each $c_{ij}$ occurs 
in a monomial, we are not particularly interested in the \textit{order}. Sometimes it is easier, then, to simply regard these as weak compositions:
\begin{defn}
	Let $n$ and $r$ be integers as usual. Then denote by $[a_1,\dots,a_n]$ the \textbf{weight} corresponding to 
	$(i_1,\dots,i_r)\in I(n,r)$ where for each $i$,
	\[a_i=\#\{k\in\underline r| i_k=i\}\]
	Denote by $\Lambda(n,r)$ the collection of all weights. 
\end{defn}
\begin{rmk}
	Another way to realize $\Lambda(n,r)$ is in the presentation 
	\[\Lambda(n,r)=\left\{[a_1,\dots,a_n]\left|\sum_i a_i=r\right.\right\},\]
	or as the set of compositions of $r$ into $n$ parts (allowing zeros).
	
	Yet another is to think of $\Lambda(n,r)$ as the set of $\frakS_r$ orbits in $I(n,r)$ (where now two objects 
	are distinguished only if their ``contents'' vary).
\end{rmk}
Recall (c.f. \ref{def:schur-alg}) that we had that $\xi_{i,j}(c_{a,b})=1$ if and only if $(i,j)\sim(a,b)$. Because of this, it makes sense (if $\alpha$ is the 
weight of $i$) to write 
\[\xi_{\alpha}\eqdef \xi_{\alpha,\alpha}\eqdef \xi_{i,i}\]
since the action is the same irrespective of the choice of representative $i$ of $\alpha.$

Notice that the weights admit a $\frakS_n$ action 
\[\sigma\cdot [a_1,\dots,a_n]=[a_{\sigma(1)},\dots,a_{\sigma(n)}]\]
then 
\begin{defn}
	$\Lambda_+(n,r)$ is the orbit space of $\Lambda(n,r)$ under the above $\frakS(n)$ action.
\end{defn}
\begin{rmk}
	The above are called the \textbf{dominant weights} in $M(n,r)$. Since each orbit $\alpha$ contains an element $[a_1,\dots,a_n]\in\alpha$ such that 
	\[a_1\ge a_2\ge\cdots\ge a_n\]
	we will often identify weights with their weakly-decreasing representative.

	Sometimes we will refer to the dominant weight representing the orbit of $i\in I(n,r)$ as the \textbf{shape of $i$.}
\end{rmk}

The theory of weights in representations of $\Gamma$ closely mirrors similar decompositions in other 
Artinian algebras: first we identify a family of (mutually orthogonal) idempotents:
\begin{lem}
	For $\alpha\in\Lambda(n,r)$ and $i,j\in I(n,r)$,
	\[\xi_\alpha\xi_{i,j}=\begin{cases}
		\xi_{i,j}, & i\in\alpha\\
		0, &\text{otherwise}
	\end{cases}\quad\text{and}\quad\xi_{i,j}\xi_\alpha=\begin{cases}
		\xi_{i,j}, & j\in\alpha\\
		0, &\text{otherwise}
	\end{cases}\]
\end{lem}
\begin{prf}
	We can compute the image of these on the $c_{a,b}\in A(n,r)$:
	\begin{align*}
		\xi_\alpha\cdot \xi_{i,j}(c_{a,b})&=\sum_k \xi_\alpha(c_{a,k})\xi_{i,j}(c_{k,b})\\
		&= \xi_\alpha(c_{a,a})\xi_{i,j}(c_{a,b})
	\end{align*}
	where above we used that $\xi_{\alpha}(c_{i,j})=0$ unless $i=j$. But 
	\[\xi_\alpha(c_{a,a})=\begin{cases}
		1, & a\in\alpha\\ 0, & \text{otherwise}
	\end{cases}\]
	so 
	\[\xi_\alpha\cdot \xi_{i,j}(c_{a,b})=\begin{cases}
		\xi_{i,j}(c_{a,b}),& a\in\alpha\\ 0,& \text{otherwise}
	\end{cases}\]
	but in the case where $a\in\alpha$ and $\xi_{i,j}(c_{a,b})\ne 0$, this implies that $i\sim a$, so $i\in \alpha$. So finally,
	\[\xi_\alpha\cdot \xi_{i,j}(c_{a,b})=\begin{cases}
		\xi_{i,j}(c_{a,b}),& i\in\alpha\\ 0,& \text{otherwise}
	\end{cases}\]
	and since this holds for any $c_{a,b}$, the left-hand side is proven. A symmetric argument goes through for the right-hand side.
\end{prf}

For the next step, we decompose the identity into a sum of these idempotents:
\begin{lem}\label{lem:decomp-one}
	We have the decomposition 
	\[\1 = \sum_{\alpha\in\lambda(n,r)} \xi_\alpha.\]
\end{lem}
\begin{prf}
	On the one hand, for any $c_{a,b}\in A(n,r)$, $\1(c_{a,b})=\delta_{a,b}$. On the other hand, for any $\alpha$,
	\[\xi_\alpha(c_{a,b})=0\]
	when $a\ne b$ \textit{or when $a\notin \alpha$}. 
	
	Therefore when $a=b$, there is precisely one $\alpha$ (the orbit of $a=b$)
	such that $\xi_\alpha(c_{a,b})=1$, so putting this all together,
	\[\sum_{\alpha\in\Lambda(n,r)}\xi_\alpha(c_{a,b})=\delta_{a,b}\]
	whence these two functions are equal.
\end{prf}
\begin{rmk}\label{rmk-weight-spaces}
Using lemma~\ref{lem:decomp-one}, we can then decompose any $V\in M(n,r)$ into weight spaces:
\[V=\1\cdot V=\sum_{\alpha\in\Lambda(n,r)}\xi_\alpha V\]
which we will denote 
\[\xi_\alpha V=V^\alpha.\]
\end{rmk}

\begin{defn}\label{defn:character}
	The \textbf{formal character} of a representation $V\in M(n,r)$ is a polynomial 
	\[\Phi_V(X_1,\dots,X_n)=\sum_{\alpha\in\Lambda(n,r)}(\dim V^\alpha)X_1^{\alpha_1}\cdots X_n^{\alpha_n}=\sum_{\alpha\in\Lambda_+(n,r)}(\dim V^\alpha)m_\alpha(X_1,\dots,X_n)\]
	where $m_\alpha$ is the \textit{monomial symmetric polynomial}
	\[m_\alpha(X_1,\dots,X_n)=\sum_{\sigma\in\frakS_n}X_{\sigma(1)}^{\alpha_1}\cdots X_{\sigma(n)}^{\alpha_n}.\]
\end{defn}

\subsubsection{Irreducible representations}
The irreducible representations in $M(n,r)$ are given by a couple of results by some of the big names in representation theory: the original proof for $k=\bbC$ was proven in \cite[p.37]{schur-thesis} and then 
generalized in a later paper by Weyl \cite{weyl} and in work by Chevalley\footnote{Green \cite{green} mentions a paper by Serre: \textit{Groupes de Grothendieck des Sch\'emas en Groupes R\'eductifs D\'eploy\'es} \cite{serre-chevalley}, which 
makes mention to Chevalley's contributions in proving the existence of modules with prescribed characters. This author was unable to find Chevalley's work.}:
\begin{thm}\label{thm:irreps}
	Fix the usual lexicographical ordering on monomials in $k[X_1,\dots,X_n]$. Let $n$ and $r$ be given integers with $n\ge 1$ and $r\ge 0$ Let $k$ be an infinite field. Then 
	\begin{enumerate}
		\item For each $\lambda\in\Lambda_+(n,r)$, there exists an (absolutely) irreducible module $F_{\lambda,k}$
		in $M_k(n,r)$ whose character $\Phi_{\lambda,k}$ has leading term $X_1^{\lambda_1}\cdots X_n^{\lambda_n}$.
		\item Every irreducible $V\in M_k(n,r)$ is isomorphic to $F_{\lambda,k}$ for exactly one $\lambda\in \Lambda_+(n,r)$.
	\end{enumerate}
\end{thm}
So then the problem of classifying the simple modules (the ``basic building blocks'' in the semisimple case) is completely solved for infinite fields.
It remains to demonstrate a way to construct $F_{\lambda,k}$.
\begin{defn}
	Fix some $\lambda\in \Lambda_+(n,r)$. Notice that this corresponds to a Young diagram with $r$ boxes. Fix any labeling $1,\dots,r$ of the boxes in the 
	Young diagram corresponding to $\lambda$. Let $T$ denote the diagram for $\lambda$ along with this labeling.
	
	Let $i:\underline r\to\underline n$ be any map. Then denote by $T_i$ the \textbf{$\lambda$-tableau}, which is $T$ with the $k^{th}$ entry consisting of $i(k)\in\underline r$.
\end{defn}
\begin{rmk}
	This notation varies slightly (but not in spirit) from the notation in Green's book. He denotes the Young diagram by $[\lambda]$ and lets $T^\lambda$ be 
	the labelling of the boxes in $[\lambda]$--a bijection $[\lambda]\to\underline r$.
\end{rmk}
\begin{ex}
	Let $\lambda=(3,1,1)\in\Lambda_+(3,5)$. Thus $T$ is of shape 
	\[\ydiagram{3,1,1}\]
	Then if we fix the left-to-right/top-to-bottom ordering of the boxes in $T$ and let $i:\{1,2,3,4,5\}\to\{1,2,3\}$
	be given by $(2,1,3,3,2)$, we get the $\lambda$-tableau 
	\[T_i=\ytableaushort{2 1 3, 3, 2}\]
\end{ex}

The core tool in constructing (a basis for) the irreducible modules is in the following definiton:
\begin{defn}
	Let $\lambda\in\Lambda_+(n,r)$ be some shape with a fixed labeling and let $i,j:\underline r\to\underline n$. Then the \textbf{bideterminant of $T_i$ and $T_j$}
	is 
	\[(T_i:T_j)=\sum_{\sigma\in C(T)}\operatorname{sgn}(\sigma)c_{i,j\sigma}\in A_k(n,r)\]
	where $C(T)$ is the column stabilizer of $T$.
\end{defn}
This definition can be a bit difficult to unpack, so we give some examples:
\begin{ex}
	\begin{enumerate}
		\item $\lambda=(2,1,0)\in \Lambda_+(3,3)$\[\ytableausetup{nosmalltableaux}\left(\ytableaushort{1 2,3}:\ytableaushort{3 1,2}\right)=\left|\begin{array}{cc}
			c_{13} & c_{12}\\ c_{33} & c_{32}
		\end{array}\right|c_{21}=(c_{13}c_{32}-c_{12}c_{33})c_{2,1}=c_{(1,2,3),(3,1,2)}-c_{(1,2,3),(2,1,3)}\]
		\item $\lambda=(n,0,\dots,0)\in\Lambda_+(m,n)$\[\left(\begin{ytableau} a_1& a_2& a_3&\none[\dots] &a_n\end{ytableau}:
		\begin{ytableau} b_1& b_2& b_3&\none[\dots]&b_n\end{ytableau}\right)=c_{a_1b_1}\cdots c_{a_nb_n}\]
		\item $\lambda=(1,\dots,1,0,\dots)\in\Lambda_+(m,n)$ where $n\ge m$ \[\left(\begin{ytableau}a_1\\ a_2\\\none[\vdots]\\a_n\end{ytableau}:\begin{ytableau}b_1\\ b_2\\\none[\vdots]\\b_n\end{ytableau}\right)=
			\left|\begin{array}{ccc}c_{a_1b_1} & \cdots & c_{a_1b_n}\\
			\vdots & \ddots & \vdots\\
			c_{a_nb_1} & \cdots & c_{a_nb_n}
			\end{array}\right|\]
	\end{enumerate}
\end{ex}

In the following, let $l:\underline r\to\underline n$ be $(1,\dots,1,2,\dots,2,3,\dots)$ such that for any shape $\lambda$ the 
$\lambda$-tableau $T_l$ is 
\[\begin{ytableau}
	1 & 1 &\none[\dots] &\none[\dots] &1\\
	2 & 2 &\none[\dots] &2\\
	\none[\vdots]\\
	k
\end{ytableau}\ytableausetup{smalltableaux}\]
with $i$ in every box on the $i^{th}$ row from the top.

\begin{defn}
	Define, for every shape $\lambda\in\Lambda_+(n,r)$, the module
	\[D_{\lambda,k}=\langle(T_l:T_i)\rangle_{i\in I(n,r)}\]
	where $l$ is the filling defined above.
\end{defn}
According to \cite{green}, these modules were originally called ``Weyl modules'', while he (and we)
reserve this name for the contravariant dual of these objects. To construct them, define the map 
\begin{equation}\label{eqn:pimap}
	\pi:E^{\otimes r}\to D_{\lambda, k},
\end{equation}
and we get objects originally defined in Carter and Lusztig's treatment of modular representations of $\GL_n$ \cite{carter-lusztig}
and tweaked by Green in \cite{green}:
\begin{defn}
	Given a shape $\lambda$, the \textbf{Weyl module of shape $\lambda$ over $k$} is 
	$V_{\lambda, k}\eqdef N^\perp$ where 
	\[N\eqdef\ker\pi\hookrightarrow E^{\otimes r}\to D_{\lambda,k}\]
	and the orthogonal complement of $N$ is taken with respect to the canonical contravariant form on $E^{\otimes r}$ that has the property $\langle e_i,e_j\rangle=\delta_{ij}$.
\end{defn}

In their original paper \cite[p.218]{carter-lusztig}, Carter and Lusztig showed that these modules are, in fact, generated as $S(n,r)$-modules by a single element:
\begin{thm}\label{thm:weyl-basis}
	Let $\lambda\in\Lambda_+(n,r)$ and $T$ the Young diagram corresponding to $\lambda$. Let $l$ be the labelling above. Then 
	the element 
	\[f_l=e_l\cdot\sum_{g\in C(T)\subset\frakS_n}\operatorname{sign}(\sigma)\sigma\]
	generates $V_{\lambda,k}$ as a $S(n,r)$-module.
\end{thm}
\begin{prf}[sketch.]
	We refer the reader to Green's \cite[p.46]{green} proof for the details, but the idea is as follows: he relies on an earlier result 
	that the modules $D_{\lambda,k}$ have a basis consisting of the bideterminants 
	\[(T_l:T_i)\]
	such that $T_i$ is in ``standard form'' (meaning that it forms a valid Young tableau). One can define a nondegenerate contravariant form 
	\[(\cdot,\cdot):V_{\lambda,l}\times D_{\lambda,k}\to k\]
	by pulling back any element in $D_{\lambda,k}$ to a representative in $E^{\otimes r}$ under the map $\pi:E^{\otimes r}\to D_{\lambda,k}$.

	Recall that $V_{\lambda,k}$ is defined as the orthogonal complement (under the canonical form $\langle\cdot,\cdot\rangle$ on $E^{\otimes r}$) of $\ker\pi.$
	This gives us that $(\cdot,\cdot)$ is indeed well-defined. From there, Green does some computation to show that one can bootstrap the 
	independence of the $(T_l:T_i)$ to prove that of the set
	\[\{\xi_{jl}f_l|j\in I(n,r), T_j\text{ standard}\}\]
	forms a $(k-)$basis for $V_{\lambda,k}$, and therefore $f_l$ generates the entire module under the $S(n,r)$ action.
\end{prf}
\begin{lem}\label{lem:unique-maximal-submod}
	The modules $V_{\lambda,k}$ have a unique maximal submodule $V_{\lambda,k}^{\text{max}}$
\end{lem}
\begin{prf}[{\cite[p.47]{green}}]
	Begin by noticing that the weight space $V_{\lambda,k}^\lambda$ is spanned by the single element $f_l$. This is because
	\[\xi_l\cdot\xi_{il}f_l=\delta_{il}f_l\]
	so the only nonzero basis vector from the proof of thm.~\ref{thm:weyl-basis} is $f_l$ itself. Since $f_l$ generates 
	all of $V_{\lambda,k}$ as an $S(n,r)$-module, however, any proper submodule $M$ of $V_{\lambda,k}$ must be contained in the 
	complement of $V_{\lambda,k}^\lambda.$ Thus the sum of all proper submodules is contained in the complement of this 
	weight space, and is therefore proper! This sum is our $V_{\lambda,k}^\text{max}$
\end{prf}

We are finally in good shape to compute the irreducible modules promised to us in thm.~\ref{thm:irreps}. We define 
\[F_{\lambda, k}=V_{\lambda,k}/V_{\lambda,k}^\text{max}\]
where $V_{\lambda,k}^\text{max}$ is the unique maximal submodule guaranteed to us by lemma~\ref{lem:unique-maximal-submod}. It remains to show 
that the $F_{\lambda,k}$ have the requisite characters $\Phi_{\lambda,k}$. But notice that $V^\lambda_{\lambda,k}$ is one-dimensional, so 
the character (c.f. definition \ref{defn:character}) of $V_{\lambda, k}$ is of the form 
\[m_\lambda(X_1,\dots,X_n)+\sum_{\lambda\ne\alpha\in\Lambda_+(n,r)} \dim V_{\lambda,l}^\alpha m_\alpha(X_1,\dots,X_n)\]
but since each $V_{\lambda,k}^\alpha$ is contained in $V_{\lambda,k}^\text{max}$, it occurs as a weight space of this maximal submodule with the 
same multiplicity. Therefore the character of $V_{\lambda,k}^\text{max}$ is 
\[\sum_{\lambda\ne\alpha\in\Lambda_+(n,r)} \dim V_{\lambda,l}^\alpha m_\alpha(X_1,\dots,X_n)\]
so we can conclude that 
\[\Phi_{V_{\lambda,k}}(X_1,\dots,X_n)=m_\lambda(X_1,\dots,X_n)=X_1^{\lambda_1}\cdots X_n^{\lambda_n}+\cdots\]
which has leading term (under the lexicographic ordering) precisely what we wanted.


\subsection{Explicit examples for comparison}
To demonstrate the theory developed above, we begin a computation (in a simple case) of the isomorphism classes of irreducible 
representations of both $S_\bbC(2,2)$ and $\frakS_2$.

\subsubsection{The symmetric group on two letters}
The representation theory (over $k=\bbC$) of $\frakS_2$ is as simple as it comes: of course $\frakS_2\cong \bbZ/2\bbZ$ and we know that 
there are $|G|$ nonisomorphic irreducible representations of an abelian group $G$ over $\bbC$. Since we are talking about a symmetric group, 
we can realize these as the trivial and sign representations, represented by the Young diagrams:
\[\ydiagram{2}\quad\text{and}\quad\ydiagram{1,1}\]

As submodules of the regular representation $k\frakS_2= k e\oplus k(1\,2)$, we can construct these as $\langle e+(1\, 2)\rangle$ (trivial representation) and $\langle e-(1\,2)\rangle$ (sign representation).

\subsubsection{The Schur algebra \texorpdfstring{$S_\bbC(2,2)$}{S(2,2)}}
Since $\ch\bbC=0$, corollary~\ref{cor:semisimple} implies that $S_\bbC(2,2)$ is semisimple, so it suffices to identify the irreducible submodules therein.
We know 
\[S=S_\bbC(2,2)\cong \bbC^2\otimes\bbC^2\]
so $\dim_\bbC S=4.$ The theory outlined above gives us that isomorphism types of irreducible modules are in bijection with compositions of 2 of length 2, meaning 
we have two isomorphism types: one corresponding to $\lambda_1=(1,1)$ and one corresponding to $\lambda_2=(2,1)$. 

Using the construction of $D_{\lambda,\bbC}$ from above, we can compute these two irreducible modules explicitly:

\begin{ex}[$\mathbf{\lambda_1=(1,1)}$]
 In this case our shape is $(1,1)$, corresponding to the Young diagram 
\[\ydiagram{1,1}\]
and then $D_{\lambda_1,\bbC}$ is spanned by the element
\[(T_l:T_{(2,1)})=\left(\ytableaushort{1,2}:\ytableaushort{2,1}\right)=c_{12}c_{21}-c_{11}c_{22}=c_{(1,2),(2,1)}-c_{(1,2),(1,2)}\in A_\bbC(2,2)\]
since all other bideterminants of this shape are zero or linearly dependent. Thus this is a one-dimensional irreducible representation.
\end{ex}
\begin{ex}[$\mathbf{\lambda_2=(2,0)}$]
Now our shape is $(2,0)$, corresponding to the diagram
\[\ydiagram{2}.\]
The bideterminants here are 
\begin{align*}
	(T_l:T_{(1,1)})=\big(\ytableaushort{1 1}:\ytableaushort{1 1}\big)=c_{11}^2\\
	(T_l:T_{(1,2)})=(T_l:T_{(2,1)})=c_{11}c_{12}\\
	(T_l:T_{(2,2)})=c_{12}^2
\end{align*}
So we have a three-dimensional irreducible representation spanned by $\langle c_{11}^2,c_{11}c_{12},c_{12}^2\rangle$.
\end{ex}
Since these are the only two Young diagrams of size two, these examples form a complete list of isomorphism classes of irreducible representations of $S_\bbC(2,2)$.

If we prefer instead to recognize our irreducibles as submodules of $E^{\otimes 2}=(k e_1\oplus k e_2)^{\otimes 2}$ (giving us a more obvious action by our algebras), 
we can use the short exact sequence 
\[0\to N\hookrightarrow E^{\otimes 2}\twoheadrightarrow D_{\lambda,\bbC}\to 0\]
to define the $N=\ker\pi$, where $\pi$ is the map defined in equation (\ref{eqn:pimap}) above.
Then we can compute the orthogonal complement to $N$ to get $V_{\lambda,\bbC}$.
We can compute:
\[V_{\lambda_1,\bbC}=\langle e_1\otimes e_2-e_2\otimes e_1\rangle\]
and
\[V_{\lambda_2,\bbC}=\langle e_1\otimes e_1, \,e_1\otimes e_2+e_2\otimes e_1, \,e_2\otimes e_2\rangle.\]



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\newpage
\section{The Schur-Weyl Functor}
From the discussion in the last section it is evident that the combinatorics behind the representation theory of $S(n,r)$ and $\frakS_r$ have some intersections
in their use of Young tableaux and this connection is more than superficial. In fact, there is a functor relating the representations
of these two objects in the following way:
\subsection{Construction of the functor \texorpdfstring{$\calF$}{F}}

Let $V\in M_k(n,r)$ be a $S(n,r)$-representation and select any weight $\alpha\in\Lambda(n,r)$. Then the weight space (cf. rmk~\ref{rmk-weight-spaces})
\[V^\alpha=\xi_\alpha V\]
becomes a $S(\alpha)\eqdef\xi_\alpha S(n,r)\xi_\alpha$-module using the action from $S(n,r)$. Now if we allow $r\le n$ and let
\[\omega=(1,\dots,1,0,\dots,0)\in\Lambda(n,r)\]
notice that $S(\omega)$ is spanned by the elements
\[\xi_\omega\xi_{i,j}\xi_\omega,\quad i,j\in I(n,r)\]
but by the multiplication rules established in the definition of $S(n,r)$, these are nonzero precisely when 
$i$ and $j$ are both of shape $\omega$. So then since $\xi_{i,j}=\xi_{i\sigma,j\sigma}$ for all $\sigma\in\frakS_r$, we can take as
a basis of $S(\omega)$ the set 
\[\{\xi_{u\pi,u}|\pi\in\frakS_r\}\]
where $u=(1,2,\cdots,r)\in I(n,r)$.

To prove the next statement we require a computational result.
\begin{lem}\label{lem:somega-mult}
	If $u=(1,2,\dots,r)\in I(n,r)$, then for all $\pi,\sigma\in\frakS_r$,
	\[\xi_{u\pi,u}\cdot \xi_{u\sigma,u}=\xi_{u\pi\sigma,u}.\]
\end{lem}
\begin{prf}
	Using the formulas for multiplication in $S(n,r)$, recall that 
	\begin{equation}
		\xi_{u\pi,u}\cdot\xi_{u\sigma,u}=\sum Z_{i,j} \xi_{i,j}\label{eq:1}
	\end{equation}
	where 
	\[Z_{i,j}=\#\{s\in I(n,r)|(u\pi,u)\sim(i,s)\text{ and }(u\sigma,u)\sim (s,j)\}.\]
	Then for each $i,j$, since $u=(1,2,\dots,r)$ has no stabilizer in $\frakS_r$, there is a unique 
	$g$ such that $u\pi g=i$, meaning that $s=ug$. 

	But then this fixes (again a unique) $h\in\frakS_r$ such that $u\sigma h=s=u g$ whence $\sigma h= g$. 
	One computes that 
	\[u\pi\sigma h = u\pi g=i\quad\text{and}\quad uh = j\]
	therefore since in the above computation $s$ was completely determined by $i$, we have
	\[Z_{i,j}=\left\{\begin{array}{lr}
		1, &  (i,j)\sim(u\pi\sigma,u)\\
		0, & \text{otherwise}
	\end{array}\right.\]
	and the result follows.
\end{prf}
Using this result, we prove a more obviously useful statement:

\begin{lem}
	$S(\omega)\cong k\frakS(r)$.
\end{lem}
\begin{prf}
	Define the map $\varphi:S(\omega)\to k\frakS_r$ on the basis above to be 
	\[\varphi (\xi_{u\pi,u})=\pi\]
	and extending $k$-linearly.

	This is a homomorphism since 
	\[\varphi(\xi_{u\pi,u}\xi_{u\sigma,u})=\varphi(\xi_{u\pi\sigma,u})=\pi\sigma=\varphi(\xi_{u\pi,u})\varphi(\xi_{u\sigma,u})\]
	and it is bijective since it is bijective on the respective bases and is thus bijective as a linear map.
\end{prf}
The upshot of these lemmas is that one can define the \textbf{Schur-Weyl functor} 
\[\calF:M_k(n,r)\to \Rep(\frakS_r)\]
via the map that sends any representation $V$ to its $\omega$ weight space $V^\omega\in \lmod {S(\omega)}\simeq \Rep(\frakS_r)$.

\subsection{The general theory}
The idea of the Schur functor fits into a larger context: Let $S$ be a $k$-algebra and let $M\in\lmod S$. Furthermore, let $e\in S$ be a (nonzero)
idempotent. Then one can define a functor 
\[\calF:\lmod S\to\lmod {eSe}\quad\text{via}\quad V\mapsto eV.\]
An important property of this functor is 
\begin{prop}\label{prop:F-irred}
	The image of an irreducible $S$ module under the functor $\calF$ above is zero or irreducible.
\end{prop}
\begin{prf}
	Let $e\in S$ be the idempotent in the discussion above and let $W\subseteq eV$ be any nonzero $eSe$-submodule.
	Then notice that $eW$ is a nonzero $S$-module contained in $e^2V=eV$, so $eW=eV$.
	But since $eW\subseteq W$, this forces $W=eV$, so $\calF(V)$ is irreducible.
\end{prf}

Next, a discussion in Green \cite[p. 56]{green} gives us a natural thought process to follow in constructing a partial inverse to this functor. 
Let $\calG:\lmod{eSe}\to\lmod S$ be an extension of scalars: specifically, if $M\in\lmod{eSe}$, then 
\[\tilde\calG(M)=Se\otimes_{eSe}M.\]
This is clearly functorial and furthermore satisfies the property that 
\[\calF\circ\tilde\calG(M)=\calF(Se\otimes_{eSe}M)=e(Se\otimes_{eSe}M)=eSe\otimes_{eSe} M\cong e\otimes_{eSe}M\cong M\]
so it is a right inverse (up to isomorphism) to $\calF$---a good candidate for our purposes. 
\begin{rmk}
	It is easy to prove the fact, which I glossed over above, that $M\cong e\otimes M$ via the $eSe$-isomorphism $m\mapsto e\otimes m$.
\end{rmk}

What we are really looking for, however, is a functor that sends irreducible modules to irreducibles. It can be shown that $\tilde G$ 
\textit{does not} satisfy this property, so we define 
\begin{defn}
	If $M\in\lmod S$ and $e\in S$ is an idempotent, denote by $M_{(e)}$ the largest $S$-submodule of $(1-e)M$.
\end{defn}
\noindent which enables us to define the functor 
\[\calG:\lmod{eSe}\to \lmod S\quad\text{via}\quad M\mapsto \tilde\calG(M)/\tilde\calG(M)_{(e)}.\]
This leads to the result:
\begin{prop}
	If $M\in \lmod{eSe}$ is irreducible, then so is $\calG(M)$.
\end{prop}
\begin{prf}
	Let $W$ be an $S$-module such that 
	\[\tilde\calG(M)_{(e)}\subseteq W\subseteq \tilde\calG(M)\]
	Then consider multiplying by $e$ in the above inculsions:
	we get
	\[0=e\tilde\calG(M)_{(e)}\subseteq eW\subseteq e\tilde \calG(M)=\calF\circ\tilde\calG(M)\simeq M\]
	which, by the irreducibility of $M$, forces either $eW=0$ (in which case $W\subseteq\tilde\calG(M)_{(e)}$ and we are done)
	or else $eW=e\tilde\calG(M)$.

	In this latter case, we find 
	\[\tilde\calG(M)= Se\otimes M\simeq Se\otimes eSeM=S(eSe\otimes M)=S(e\tilde\calG(M))=SeW\subseteq W\]
	Thus we can conclude that $W=\tilde\calG(M)$, so $\calG(M)$ has no nontrivial proper submodules, so it is simple.
\end{prf}

\subsection{Properties of \texorpdfstring{$\calF$ and $\calG$}{F and G}}
Returning to the specific case of $S=S(n,r)$ and $eSe\cong\frakS_r$, the theory developed in the last part
gives us a pair of functors
\[\calF:M(n,r)\to \lmod{\frakS_r},\qquad \calG:\lmod{\frakS_r}\to M(n,r),\]
each of which preserve irreducibility. We also have that
\begin{prop}
	If $M\in M(n,r)$ is irredicible and if $eM\ne 0$, then $\calG\circ\calF(M)=\calG(eM)\cong M.$
\end{prop}
\begin{prf}
	Notice by prop.~\ref{prop:F-irred} and the following discussion that $eM$ is irreducible and (by assumption) nonzero, so
	\[\calF\circ\calG(eM)\cong eM\]
	and since 
	\[0\ne eM\subseteq M\]
	and $M$ is irreducible, $eM=M$.
\end{prf}
This leads us to the following realization:
\begin{cor}
	If $\{M_\alpha\}_{\alpha\in\calI}$ is a complete collection of irreducible modules over $S(n,r)$,
	then there exists a subset $\calJ\subseteq\calI$ such that $\{\calF(M_\alpha)\}_{\alpha\in\calJ}$
	is a complete (and irredunant) set of irreducible $\frakS_r$-modules.

	Furthermore, any index $j\in\calJ$ satisfies $\calG\circ\calF(M_j)\cong M_j$.
\end{cor}

Whenever we have a pair of opposing functors like this, we hope that we can prove that they 
tie the two categories together in a nice way, and in fact we can! A standard categorical fact,
reprinted here from Emily Riehl's book, empowers us to make our last proof:
\begin{prop}[{\cite[prop.~4.2.6]{riehl}}]
	Given a pair of opposing functors $\calF:\calC\rightleftarrows\calD:\calG$, is an adjoint pair (with $\calF\ladjointto\calG$) if and only if 
	there exist unit and counit maps
	\[\eta:1_\calC\to \calG\calF\qquad\text{and}\qquad \varepsilon:\calF\calG\to 1_\calD\]
	satisfying the \textit{triangle axioms} illustrated in figure \ref{fig:triangles}.
\end{prop}
\begin{figure}
	\centering
	\begin{tikzcd}
		\calF\ar[r,"\calF\eta"]\ar[dr,"1_\calF",swap] & \calF\calG\calF\ar[d,"\varepsilon\calF"]\\
		& \calF
	\end{tikzcd}\qquad
	\begin{tikzcd}
		\calG\ar[r,"\eta\calG"]\ar[dr,"1_\calG",swap] & \calG\calF\calG\ar[d,"\calG\varepsilon"]\\
		& \calG
	\end{tikzcd}
	\caption{The triangle axioms}
	\label{fig:triangles}
\end{figure}

\begin{thm}
	The functors are adjoints.
\end{thm}
{\color{red} Figure out what direction the adjunction goes and prove this!}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage
\section{Strict polynomial functors}
The theory of strict polynomial functors has its genesis in the idea of \textit{polynomial maps between vector spaces},
or equivalently the rational maps between the schemes they represent. The category of vector spaces with these polynomial maps---and 
more specifically, the representaion category associated to it---gives the category $\Rep \Gamma^d_k$ of strict polynomial functors. 

Originally definied by Friedlander and Suslin in \cite{friedlander-suslin}, the authors there showed that 
the category $\lmod{S(n,r)}$ is equivalent to this category, introducing the language of polynomial functors as 
a way to understand the structure of representations of the Schur algebras. 

This process was carried out by Krause \cite{krause-strict-poly-func} and his students Aquilino and Reischuk \cite{aquilino-reischuk}.
In the former, Krause identifies projective generators $\Gamma^{d,V}$ for $\Rep\Gamma^d_k$ and defines the tensor product 
by defining it for projectives and taking the appropriate colimits. In the latter paper, the construction 
is further elucidated and it is proven that the Schur-Weyl functor $\calF$ is monoidal.

\subsection{Polynomial maps}
{\color{red} TODO: Rewrite this to account for the fact I am now using the algebraic definition of polynomial maps instead of the geometric one.}

Let $V,W$ be vector spaces over a field $k$. There are many equivalent formulations of polynomial maps between such spaces, 
but one that this author of this paper finds particulaly motivating is the following:
\begin{defn}\label{defn:poly-maps}
	Let $V,W$ be as above. Then the set of \textbf{polynomial maps from $V$ to $W$} is defined to be 
	\[\Hom_\text{Pol}(V,W)\eqdef \Hom_{\Sch/k}(V,W).\]
\end{defn}

To make sense of this definition, one recalls that every $V\in\Vectk$ corresponds to an affine $k$-scheme 
$\Spec S^\ast(V^\vee)=V\otimes_k-$ (which we, through an abuse of notation, again denote $V$) represented by the symmetric algebra of the dual of $V$. Thus the polynomial maps
are precisely the rational maps one considers between these objects in their algebro-geometric realizations.

\begin{rmk}
	In Friedlander and Suslin's original paper, they define these maps abstractly as $S^\ast(V^\vee)\otimes W$. That this 
	agrees with our definition (assuming that $V$ and $W$ are finite dimensional) follows from the following series of isomorphisms:
	\begin{align*}
		\Hom_\text{Pol}(V,W)&\eqdef\Hom_{\Sch/k}(V,W)\\
		&\simeq\Hom_{\Alg_k}(S^\ast(W^\vee),S^\ast(V^\vee))\\
		&\simeq\Hom_{\Alg_k}(W^\vee,S^\ast(V^\vee))\\
		&\simeq W\otimes S^\ast(V^\vee)
	\end{align*}
	where we used above properties of affine schemes and standard facts of the linear algebra of finite dimensional vector spaces as well as the fact that 
	a map from $S^\ast(V)$ is determined uniquely by its images on $V$.
\end{rmk}
For reasons that will become apparent shortly, it is easier to use the above remarks to define a 
polynomial map in the following way:
\begin{defn}
	If $V,W\in\Vectk$ are finite dimensional, a \textbf{polynomial map $f:V\to W$} can be alternatively defined as an element 
	\[f\in W\otimes S^\ast(V^\vee)\cong\Hom_{\Sch/k}(V,W)\]
	through the identifications above.
\end{defn}

The upshot to this seemingly more \textit{ad hoc} definition is that, while it introduces the restriction of finite dimensionality (which will suffice for our 
definitions anyways), it enables us to make more simple the following idea:
\begin{defn}\label{def:homog-poly-map}
	Let $V$ and $W$ be vector spaces. Then a map $f\in \Hom_\text{Pol}(V,W)$ is called \textbf{homogeneous degree $d$} if 
	it corresponds (under the isomorphisms above) to an element 
	\[f\in W\otimes S^d(V^\vee).\]
\end{defn}
This is clearly a tangible and sensible way to define a degree $d$ map and it is less obvious how to define a property 
on the map of corresponding varieties that achieves the same goal. We will see in the next subsection other ways to define this 
notion that may appeal more to representation theorists.
\begin{ex}
	Here are some examples of polynomial maps:
	\begin{itemize}
		\item The identity (scheme) map $\id:V\to V$ is a (homogeneous degree 1) polynomial map. This corresponds to the element 
		\[\sum_{i=1}^n v_i\otimes v_i^\vee\in V\otimes S^\ast(V^\vee)\]
		where $v_1,\dots,v_n$ is a basis for $V$.
		\item If $V=\langle v_1,\dots,v_n\rangle$ and $W=\langle w_1,\dots,w_m\rangle$, the element
		\[\sum_1^m w_i\otimes (v_i^\vee\otimes v_i^\vee)\]
		gives rise to a map of algebras that sends basis element
		\[\sum_{\sigma\in\frakS_k}w_{i_{\sigma(1)}}^\vee\otimes \cdots\otimes w_{i_{\sigma(k)}}^\vee\mapsto \sum_{\sigma\in\frakS_k}v_{i_{\sigma(1)}}^\vee\otimes v_{i_{\sigma(1)}}^\vee\otimes \cdots\otimes v_{i_{\sigma(k)}}^\vee\otimes v_{i_{\sigma(k)}}^\vee\]
		which corresponds to a homogeneous degree 2 polynomial (scheme) map $V\to W$.
	\end{itemize}
\end{ex}

\subsection{The categories \texorpdfstring{$\calP_k$}{Pk} and \texorpdfstring{$\Rep \Gamma^d_k$}{Rep Gdk}}
Before we define these categories we should describe the objects in question!
\begin{defn}
	A \textbf{strict polynomial functor} is a functor $T:\Vect_k\to \Vect_k$ such that for any $V,W\in\Vect_k$,
	the map on $\Hom$s
	\[T_{V,W}:\Hom_k(V,W)\to \Hom_k(T(V),T(W))\]
	is a polynomial map. That is,
	\[T_{V,W}\in\Hom_\text{Pol}\big(\Hom_k(V,W), \Hom_k(T(V),T(W))\big)\]
\end{defn}

Earlier I promised that we would have a more representation-theoretic interpretation of the homogeneous degree 
of a strict polynomial functor. I am nothing if I am not true to my word:
\begin{lem}[Lem. 2.2 in \cite{friedlander-suslin}]
	Let $T$ be a strict polynomial functor and let $n\ge 0$ be an integer. Then the following conditions are equivalent:
	\begin{enumerate}
		\item For any $V\in\Vectk$, any field extension $k'/k$ and any $0\ne\lambda\in k'$, the $k'$-linear 
		map $T_{k'}(\lambda\cdot 1_{V_{k'}})\in\End_{k'}(T(V)_{k'})$ coincides with $\lambda^n1_{T(V)_{k'}}$.
		\item For any $V\in\Vectk$, $n$ is the only weight of the representation of the algebraic group $\Gm$ in $T(V)$
		obtained by applying $T$ to the evident representation of $\Gm$ in $V$.
		\item For any $V,W\in\Vectk$, the polynomial map 
		\[T_{V,W}:\Hom_k(V,W)\to \Hom_k(T(V),T(W))\] 
		is homogeneous of degree $n$ (in the sense of \ref{def:homog-poly-map}).
	\end{enumerate}
\end{lem}
\begin{prf}
	\color{red} Spell this out. 
\end{prf}

\begin{defn}
	The category $\calP_d$ is the full subcategory 
	\[\calP_d\subset\Func(\Vectk,\Vectk)\]
	whose objects are the \textbf{strict polynomial functors of degree $d$.}
\end{defn}

\begin{thm}
	The map
	\[\Psi:\calP_d\to \lmod {S(n,d)}\]
	given by evaluation at $k^n$:
	\[T\mapsto T(k^n)\]
	is an equivalence of categories.
\end{thm}
\begin{prf}
	\color{red} refactor the proof from Friedlander and Suslin.
\end{prf}

\subsubsection{Yet another category}
Just when you thought you had enough categories to consider, Krause developed a new category that more succinctly captures
the stucture of homogeneous degree $d$ polynomial maps: there the author changes the domain of these functors 
to encode the desired properties automatically.
\begin{defn}
	Let $k$ be any commutative ring. Then $P_k\subset \Vect_k$ is the full subcategory of finitely-generated projective $k$-modules.

	Define $\Gamma^d P_k$ to be the category of \textbf{divided powers}---the objects are the same as those of $P_k$, but such that 
	\[\Hom_{\Gamma^dP_k}(V,W)=\Gamma^d\Hom_{P_k}(V,W)\]
	where $\Gamma^d X=(X^{\otimes d})^{\frakS_d}$ denotes the \textbf{$d^{\text{th}}$} divided powers of the $k$-module $X$.

	Finally, as a matter of notation, let 
	\[\Rep\Gamma^d_k=\Rep\Gamma^dP_k=\Func(\Gamma^dP_k,\lmod k)\]
	which we (suggestively) call the \textbf{category of homogeneous degree $d$ strict polynomial functors.}
\end{defn}
\begin{rmk}
	Of course, when $k$ is a field, we get that $P_k=\Vectk$ and an element
	\[T\in\Rep\Gamma^d_k=\Func(\Gamma^d\Vectk,\Vectk),\]
	is a functor that, on objects, is a map $\Vectk\to \Vectk$ and on morphisms is of the form 
	\[T_{VW}:\Hom_{\Gamma^d\Vectk}(V,W)=\Gamma^d\Hom_k(V,W)\to \Hom_k(T(V),T(W))\]
	which, while not exactly our definition of a polynomial map, suggests some level of similarity.
\end{rmk}

{\color{red} Finish up proving that this category is also equivalent. Maybe try to see if I can cook up an equivalence directly between $\calP_d$ and $\Rep\Gamma^d_k?$}

\subsection{Monoidicity of \texorpdfstring{$\calF$}{F}}
One of the upshots of Krause's reformulation of strict polynomial functors is that it admits a more obvious monoidal 
structure. His construction of the tensor product on $\Rep\Gamma_k^d$ takes the following tack: notice that the Yoneda embedding 
is a map 
\[y:(\Gamma^dP_k)\op\to \Rep\Gamma^d_k\]
sending each object $V\mapsto \Hom_{\Gamma^dP_k}(V,-)$. Furthermore, the embedding $y$ is dense!
\begin{lem}\label{lem:yoneda-dense}
	Given a small category $\calC$, let $y$ be the Yoneda embedding 
	\[y:(\calC)\to \Func(\calC\op,\Set)=\PreSh(\calC).\]
	Then every element in $\PreSh(\calC)$ is (in a canonical way) a colimit of elements in the image of $y$. That is, for some collection of $C_i\in \calC$,
	\[X=\colim_{\longrightarrow i}y(C_i)\]
\end{lem}
To prove this lemma, let us remind you of the construction called the \textbf{category of elements} of a functor $\calF:\calC\to \Set$. It elements are 
pairs $(C,x)$ where $C\in\calC$ and $x\in \calF(C)$ is a point. 

Morphisms between two objects
\[f:(C,x)\to (C',y)\]
are honest morphisms $f:C\to C'$ in $\calC$ such that the set morphism
\[\calF(f):\calF(C)\to \calF(C')\]
has the property that 
\[\calF(f)(x)=y.\]
This category gives us a way to work with elements of a category ``locally'' even if the category $\calC$ 
is not concrete.

\begin{prf}[of \ref{lem:yoneda-dense}]
	The following proof is a specialized form of one in \textit{Sheaves in Geometry and Logic} \cite[41-43]{maclane-moerdijk}. 
	Define the functor
	\[R:\PreSh(\calC)\to \PreSh(\calC)\quad\text{via}\quad E\mapsto \Hom_{\hat\calC}(y(-),E).\]
	Define also the opposing functor 
	\[L:\PreSh(\calC)\to \PreSh(\calC)\quad\text{via}\quad F\mapsto \colim \calD_F\]
	where $\calD_F$ is the diagram  
	\[\scrJ\eqdef\int_\calC F\xrightarrow{\pi_\calC}\calC\xrightarrow{y}\hat\calC\]
	(this is makes sense since $\Set$ is cocomplete).

	Now we claim that $L\ladjointto R$ are a pair of adjoint functors. To prove this, it suffices to show that
	\[\Hom_{\PreSh(\calC)}(F,R(E))\cong \Hom_{\PreSh(\calC)}(L(F),E)\]
	for all $F,E\in\PreSh(\calC)$.

	Using that $\Hom:\calC\op\times\calC\to \Set$ preserves limits in each factor,
	\begin{align*}
		\Hom(L(F),E)&=\Hom(\colim_{i\in\scrJ}F(i),E)\\
		&=\lim_{i\in\scrJ}\Hom(F(i),E)
	\end{align*}

	{\color{red} One can also apparently prove this directly if specializing their proof doesn't work out.}
\end{prf}

Thus we can use this fact to describe \textbf{all} the elements in our category $\Rep \Gamma^d_k$ can be written as a colimit of 
elements of the form 
\[\Gamma^{d,V}\eqdef\Hom_{\Gamma^dP_k}(V,-)\]


\subsection{A dictionary}
{\color{red} Spell out how one can translate between the three different categories: irreducibles and tensor structure.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section{Tensor products in the derived category \texorpdfstring{$\Db(S(n,r))$}{DbS(n,r)}}
(Co)homology is a powerful tool in analyzing the composition of objects and their actions. This is evidenced 
by the sheer number of cohomology theories that are in use across many different fields. Homological computations are, 
in their nature, lossy---one is reducing the object to its signature and then we play the game of gleaning what we can 
from the structure that remains. 

It is a well-known fact of homological algebra that the cohomology of an $R$-module is independent of 
resolution by projective objects. Because of this fact, if we are interested in the homological properties of modules over a ring $R$,
it isn't useful to look at the (abelian) category $\lmod R$, but rather its ``homologically-distilled'' analog,
$\D(R)$. Throughout this section we will be relying on Weibel \cite{weibel} and his discussion on chain, homotopy, and derived categories.

\subsection{Derived categories}
In what follows, let $\calA$ denote any abelian category. If it helps, the reader can relatively safely assume that $\calA$ is $\lmod R$, the category 
of (left) $R$-modules.\footnote{That one can do this is the subject of the \textit{Freyd-Mitchell embedding theorem}, which tells us that any small Abelian category
can be embedded faithfully in $\lmod R$ for some ring $R$. Even if $\calA$ isn't small (a set), one can study it via this embedding by 
restricting attention to small abelian subcategories.} Denote by $\Ch(\calA)$ (or $\Ch(R)$ when $\calA=\lmod R$) the category of chain complexes $(C_\bullet,\partial)$
such that each $C_i\in\calA$ and $\partial\circ\partial=0$. Let $\Chb(\calA)$ denote the full subcategory of $\Ch(\calA)$ consisting of the 
complexes that are bounded---that is, $C_i=0$ for all $i>N$ and $i<M$ for some $N,M$.

Recall that a chain complex morphism\footnote{A morphism that commutes with the differential.} $f_\bullet:C_\bullet\to D_\bullet$ is a \textbf{chain nullhomotopic} in $\Ch(\calA)$ if
there exist maps $\sigma_i:C_i\to D_{i+1}$ such that we have following (non-commuting) diagram:
\begin{figure}[h]
	\centering
	\begin{tikzcd}
		\cdots\ar[r,"\partial"] &C_{n+1}\ar[d,"f_{n+1}",swap]\ar[r,"\partial"] & C_n\ar[dl,"\sigma_n"]\ar[r,"\partial"]\ar[d,"f_n"] & C_{n-1}\ar[dl,"\sigma_{n-1}"]\ar[d,"f_{n-1}"]\ar[r,"\partial"] & \cdots\\
		\cdots\ar[r,"\partial",swap] &D_{n+1}\ar[r,"\partial",swap] & D_n\ar[r,"\partial",swap] & D_{n-1}\ar[r,"\partial",swap] & \cdots
	\end{tikzcd}
\end{figure}

\noindent with the condition that (for all $n$)
\[f_n=\partial\circ\sigma_n+\sigma_{n-1}\circ \partial.\]
\begin{defn}
	Two chain maps $f,g:C_\bullet\to D_\bullet$ in $\Ch(\calA)$ are said to be \textbf{chain homotopic} if their difference is chain nullhomotopic. That is, if 
	there exists maps $\sigma_i:C_i\to D_{i+1}$ such that 
	\[f_n-g_n=\partial\circ\sigma_n+\sigma_{n-1}\circ\partial.\]
\end{defn}

A well-known lemma is the following:
\begin{lem}
	If $f$ and $g$ are chain homotopic maps, then they induce the same maps on (co)homology.
\end{lem}

Chain homotopies play the role of \textbf{homotopy equivalences} (keeping in mind the example of topological spaces with simplicial homology for intuition) and 
the fact we have nontrivial homotopy equivalences is the first indication that we aren't in the right category to study homology. A natural thing to do, then, is to 
attempt to pass to a category where we identify equivalent morphisms.

\begin{defn}
	Given the category $\Ch(\calA)$, we define the \textbf{homotopy category} $\K(\calA)$ to be the category whose objects are the 
	same as those in $\Ch(\calA)$ and whose morphisms between any two chains $C_\bullet$ and $D_\bullet$ are 
	\[\Hom_{\K(\calA)}(C_\bullet,D_\bullet)\eqdef \Hom_{\Ch(\calA)}(C_\bullet,D_\bullet)/H\]
	where $H$ consists of all chain nullhomotopic maps from $C_\bullet$ to $D_\bullet$.
\end{defn}

\begin{rmk}
	We can analogously define the category $\K^\text{b}(\calA)$ that is formed through the 
	same process after first restricting to the subcategory $\Chb(\calA)$ of bounded chain complexes.
\end{rmk}

The upshot here is that we are now closer to our (until now only implicit) goal: to find a category that captures the information 
in $\Ch(\calA)$ \textit{up to quasi-isomorphism.} One can show that, however, that in general there are quasi-isomoprhisms that are not 
homotopic to the identity map! So our job is only partially complete. 

A result of great importance to reaching our goal is that $\K(\calA)$ is \textit{triangulated} with distinguished triangles given by the mapping cones 
\[A\xrightarrow{u} B\to \cone(u)\to A[1]\]
and all triangles equivalent to them\footnote{We say a triangle $X\to Y\to Z\to X[1]$ is equivalent to a mapping cone if $X,Y,Z\in\K(\calA)$ and there exists isomorphisms (equivalently, homotopy equivalences when considered as maps in $\Ch(\calA)$)
$f,g,h$ such that the diagram in fig.~\ref{fig:tri-equiv} commutes (for some $A,B$ and $u$):
}
\begin{figure}
	\centering
	\begin{tikzcd}
		X\ar[r]\ar[d,"f"] & Y\ar[r]\ar[d,"g"] & Z\ar[r]\ar[d,"h"] & X[1]\ar[d,"{f[1]}"]\\
		A\ar[r,"u"] & B\ar[r] & \cone(u)\ar[r] & A[1]
	\end{tikzcd}
	\caption{Equivalence of triangles in $\K(\calA)$}
	\label{fig:tri-equiv}
\end{figure}

The importance of triangluated categories cannot be understated (it is critical, e.g. in the construction of the Balmer spectrum in sec.~\ref{sec:ttc}). Many people, including 
Verdier (\cite{verdier-thesis}), and Neeman (\cite{neeman-duality}, \cite{neeman-book}) have put considerable time and effort into developing a 
framework within the context of triangulated categories to enable examination and manipulation. One of the tools 
that we will now use is \textit{Verdier localization}. It closesly mirrors the idea of localization of a ring at a multiplicative 
subset (a parallel that will be extended further in the following section).

\begin{defn}
	Given a triangulated category $\calT$, a \textbf{multiplicative system} $S$ in $\calT$ is a collection of morphisms 
	in $\calT$ satisfying the following properties:
	\begin{itemize}
		\item If $s,s'\in S$, so are $s\circ s'$ and $s'\circ s$ (whenever either of these make sense).
		\item $\id_X\in S$ for all $X\in\calT$
		\item (\textbf{Ore condition}) If $t\in S$ with $t:Z\to Y$ then for every $g:X\to Y$ there are maps $f$ and $s$ (with $s\in S$) such that the diagram in figure \ref{fig:fractions} commutes. The symmetric statement also holds.
		\item (\textbf{Cancellation}) If $f,g:X\to Y$ are two morphisms, then there is an $s\in S$ with $sf=sg$ if and only if there is a $t\in S$ with $ft=gt$.
	\end{itemize}
\end{defn}
\begin{figure}
	\centering
	\begin{tikzcd}
		W\ar[d,"s"]\ar[r,"f"] & Z\ar[d,"t"]\\
		X\ar[r,"g"] & Y
	\end{tikzcd}
	\caption{Ore condition in a multiplicative system}
	\label{fig:fractions}
\end{figure}
\begin{rmk}
	Under the foresight we will eventually be inverting the elements in $S$, the Ore condition translates into the following idea: for all $g:X\to Y$ and $t:Z\to Y$ in $S$,
	\[t^{-1}g=fs^{-1}\]
	for some maps $s\in S$ and $f$. This fixes the inherent noncommutativity of function composition.
\end{rmk}
\subsubsection*{The calculus of fractions}
We can finally construct the Verdier localization of $\K(\calA)$ using a generalization of the calculus of 
fractions in localization of a ring. We will call a diagram of the form 
\[fs^{-1}:X\xleftarrow{s} X_1\xrightarrow{f} Y\]
where $s\in S$ a \textbf{fraction} and say that two fractions $fs^{-1}$ and $gt^{-1}$ are equivalent if there exists an element $X_3$ fitting 
into the commutative diagram below:
\begin{center}
	\begin{tikzcd}
		& X_1\ar[dl,swap,"s"]\ar[dr,"f"] &\\
		X & X_3\ar[u]\ar[l]\ar[r]\ar[d] & Y\\
		& X_2\ar[ul,"t"]\ar[ur,"g",swap] &
	\end{tikzcd}
\end{center}

Then from this we can define
\begin{defn}
	Let $\calT$ be a triangulated category and $S$ be a multiplicative system for $\calT$. Then the \textbf{Verdier localization of $\calT$ at $S$}, 
	$\calT[S^{-1}]$ is a category whose objects are the same as those of $\calT$ and whose morphisms are equivalence classes of 
	fractions of maps, as defined above.
\end{defn}

From this more general framework, we can very simply define the \textbf{derived category of an abelian category $\calA$}
to be 
\[\D(\calA)=\K(\calA)[W^{-1}]\]
where $W$ is the collection of weak homotopy equivalences (quasi-isomorphisms). For our purposes, it will suffice 
to restrict to the full triangulated subcategory $\K^\text{b}(\calA)$, giving us the \textbf{bounded derived category}
\[\Db(\calA)=\K^\text{b}(\calA)[W^{-1}].\]

\subsubsection*{The tensor product on \texorpdfstring{$\Db(R)$}{Db(R)}}
In the context of $R$ (where $R$ is a $k$ algebra) modules, there is a tensor bifunctor 
\[-\otimes_R-:\rmod R\times\lmod R\to \Vectk\]
and since it is right exact, but not exact, we can take the left derived functor
\[-\otimes_R^\mathbf{L}-\eqdef L^1(-\otimes_R-):\D(\rmod R)\times\D(\lmod R)\to\D(\Vectk)\]
which we call \textbf{the derived tensor product}.

More concretely, let $A,B\in\D(R)$ be two elements in the derived category of $\lmod R$. We can take a projective\footnote{Since $\Ch(R)$ has enough projectives c.f. \cite[ex. 2.2.2]{weibel}.} (\textit{a fortiori} flat)
cover $F\twoheadrightarrow A\to 0$ and complete it to a short exact sequence 
\[0\to K\to F\to A\to 0.\]
Then we get the long exact sequence for left derived functors:
\[\cdots\to K\otimes_R^\mathbf{L}B\to F\otimes_R^\mathbf{L}B\to A\otimes_R^\mathbf{L}B\to K\otimes_RB\to F\otimes_R B\to A\otimes_R B\to 0\]
where since $F$ is flat it is $(-\otimes_RB)$-acyclic and therefore $F\otimes_R^\mathbf{L}B=0$, giving us the exact sequence 
\[0\to A\otimes_R^\mathbf{L}B\to K\otimes_RB\to F\otimes_R B\to A\otimes_R B\to 0\]

\subsection{Compatibility of monoidal structures}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section{The (Balmer) spectrum of a tensor triangulated category}\label{sec:ttc}
In Paul Balmer's 2005 paper \cite{balmer-spc}, he developed a general framework for understanding the structure of certain 
kinds of categories that arose from the original constructions in algebraic geometry. Serving as a source of inspiration for Balmer, in \cite{friedlander-pevtsova-pi} Friedlander and Pevtsova proved
that the projective geometry of the cohomology ring of a finite group scheme can be recovered by looking at ``ideals'' in the category $\stmod G$ 
of stable $G$ modules.

Using this as a springboard, Balmer ported the definitions of ideals and prime ideals to tensor-triangulated categories (see below)
and proved a broader result that gives some tools for better analyzing familes of representaitons of finite groups (among other things).
\subsection{Some motivation and a definition}
Let $\calC$ be a symmetric monoidal (i.e. tensor) category with tensor product $\otimes$ and unit object $\1$. After giving some 
thought to the matter, one realizes that a ring is given by putting a ``compatible'' monoidal structure on top of an abelian group,
and to that end, one may consider the case when $\calC$ is also additive. 

This perspective gives us an interesting analogy between (unital, commutative) rings in algebra and category theory. Since every 
triangulated category is also additive, we can further specify that $\calC$ be triangulated:
\begin{defn}
	A \textbf{tensor-triangulated} category $\calC$ is both a moniodal category and a triangulated category such that 
	the monoidal structure preserves the triangluated structure. 

	As a reminder, such a category is equipped with a tensor product $-\otimes -:\calC\times\calC\to \calC$ and unit object $\1$, along with
	a collecton distinguished triangles $\calT$ comprised of objects in $\calC$ and shift functor (an auto-equivalence) $(-)[1]:\calC\to \calC$ such that:
	$-\otimes-$ is a triangulated (or exact) functor in each entry (it takes $\calT$ to itself).
\end{defn}

\subsubsection{Aside: Why triangulation?}
{\color{red} Look into and figure out why we need stability here to make sense of things.}

\subsection{Construction of the spectrum}
Once the appropriate context is identified (which is the real ingenuity of Balmer's paper), the construction 
very closely mirrors the construction seen in elementary algebraic geometry:
\begin{defn}
	Let $\calC$ be a tensor-triangulated category (TTC). Then a \textbf{(thick tensor) ideal} $I\subseteq \calC$ is a full triangulated subcategory 
	with the following conditons:
	\begin{itemize}
		\item \textit{(2-of-3 rule/Triangulation)} If $A,B,$ and $C\in\calC$ are objects that fit into a distinguished triangle
		\[A\to B\to C\to A[1]\]
		in $\calC$, and if any two of the three are objects in $I$, then so is the third.
		\item \textit{(Thickness)} If $A\in I$ is an object that splits as $A\cong B\oplus C$ in $\calC$, then both $A$ and $B$ belong to $I$.
		\item \textit{(Tensor Ideal)} If $A\in I$ and $B\in \calC$ then $A\otimes B=B\otimes A\in I$.
	\end{itemize}
\end{defn}

\begin{rmk}
	The first condition just ensures that our ideals respect the triangulated structure (and thus stability) in the parent category $\calC$. 
	The final condition is the most direct analog of an ideal and is central in the analogy between this theory and classical AG.
\end{rmk}
From here the rest of the picture is relatively straightforward:
\begin{defn}
	Let $\calC$ be a TTC as before. Then an ideal $I\subseteq\calC$ is called a \textbf{prime ideal}
	if, whenever $A\otimes B\in I$ for some $A,B\in \calC$, either $A$ or $B$ is in $I$.

	We call the collection of all primes the \textbf{spectrum} of $\calC$ and write 
	$\operatorname{Spc}(\calC)$.
\end{defn}

Here the construction varies slightly from the traditional construction of $\Spec$: we define 
\[Z(S)\eqdef\{\calP\in\Spc(\calC)|S\cap\calP=\varnothing\}\]
and define sets (for any $S\subseteq\calC$ and $A\in \calC$):
\[U(S)\eqdef \Spc(\calC)\setminus Z(S)=\{\calP\in\Spc(\calC)|S\cap \calP\ne\varnothing\}\]
and
\[\supp(A)\eqdef Z(\{A\})=\{\calP\in\Spc\calC|A\notin \calP\}\]

A routine check of the axioms shows us
\begin{lem}[2.6 of \cite{balmer-spc}]
	The sets $U(S)$ for all $S\subseteq\calC$ form a basis for a topology on $\Spc\calC$.
\end{lem}
which we call the \textbf{Zariski topology}, giving $\Spc\calC$ the structure of a topological space.

\subsection{As a locally-ringed space}
The above discussion mentions how we can construct a topological space from the set of prime thick tensor ideals 
in a TTC, but there is even more we can get: the structure of a locally-ringed space. 

To get this, we need to define the structure sheaf:
\begin{defn}
	Let $\calC$ be a tensor-triangulated category and let $\Spc\calC$ be the construction discussed above. Then the structure sheaf on $\Spc\calC$ is given by the 
	sheafification $\O_\calC$ of the presheaf 
	\[\tilde\O_\calC:\operatorname{Open}(\Spc\calC)\op\to \Ring\]
	given by 
	\[\tilde\O_\calC(U)\eqdef \End_{\calC/\calC_Z}(\1_U)\]
	where $U\subseteq\Spc\calC$ is an open set and $\calC_Z$ is the thick tensor ideal in $\calC$ supported 
	on $Z=\Spc\calC\setminus U$.
\end{defn}

\begin{rmk}
	That $\calC_Z$ is a thick tensor ideal requires some work, but it follows from work that Balmer does to 
	define a support data $(X,\sigma)$ on a tensor-triangulated category and showing that for any subset $Y\subset X$ of 
	its associated topological space, the following set 
	\[\{A\in\calC|\sigma(A)\subseteq Y\}\]
	is a thick tensor ideal of $\calC$ (c.f. lem.~3.4).
\end{rmk}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section{Questions and extensions}
\subsection*{The representation theory of \texorpdfstring{$S(n,r)$}{S(n,r)} in positive characteristic}

\subsection*{Computing the spectrum of \texorpdfstring{$\Db(S(n,r))$}{DbS(n,r)}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section*{Acknowledgements}
\label{sec:ack}
\addcontentsline{toc}{section}{\nameref{sec:ack}}
I extend my most heartfelt thanks to my advisor, Julia Pevtsova, who not only helped me immensely in setting a target 
for this project, but also introduced me to many of the classical ideas found in this paper (some times more than once). 
Her knowledge and understanding while I learned this subject has been absolutely invaluable to me.

My thanks also to my loving partner Allison, who stands beside me in good times and in bad and always patiently humors me when 
I need someone to listen to my inane ramblings.

Finally, thank you to my friends and colleagues in the University of Washington math department for many fruitful conversations 
and inspiration for ideas to investigate along the way. In particular I am indebted to (in no particular order) Thomas Carr, Sean Griffin, Sam Roven, and Cody Tipton
for all their help and support.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%  Bibliography %%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\medskip

\printbibliography
\addcontentsline{toc}{section}{References}

\end{document}